% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\usepackage[utf8]{inputenc}
\DeclareUnicodeCharacter{00A0}{\nobreakspace}
\usepackage[T1]{fontenc}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{longtable}
\usepackage{sphinx}
\usepackage{multirow}


\title{pyFASST Documentation}
\date{August 01, 2013}
\release{0.1}
\author{Jean-Louis Durrieu}
\newcommand{\sphinxlogo}{}
\renewcommand{\releasename}{Release}
\makeindex

\makeatletter
\def\PYG@reset{\let\PYG@it=\relax \let\PYG@bf=\relax%
    \let\PYG@ul=\relax \let\PYG@tc=\relax%
    \let\PYG@bc=\relax \let\PYG@ff=\relax}
\def\PYG@tok#1{\csname PYG@tok@#1\endcsname}
\def\PYG@toks#1+{\ifx\relax#1\empty\else%
    \PYG@tok{#1}\expandafter\PYG@toks\fi}
\def\PYG@do#1{\PYG@bc{\PYG@tc{\PYG@ul{%
    \PYG@it{\PYG@bf{\PYG@ff{#1}}}}}}}
\def\PYG#1#2{\PYG@reset\PYG@toks#1+\relax+\PYG@do{#2}}

\def\PYG@tok@gd{\def\PYG@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\def\PYG@tok@gu{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\def\PYG@tok@gt{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.25,0.82}{##1}}}
\def\PYG@tok@gs{\let\PYG@bf=\textbf}
\def\PYG@tok@gr{\def\PYG@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\def\PYG@tok@cm{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\def\PYG@tok@vg{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\def\PYG@tok@m{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\def\PYG@tok@mh{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\def\PYG@tok@cs{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}\def\PYG@bc##1{\colorbox[rgb]{1.00,0.94,0.94}{##1}}}
\def\PYG@tok@ge{\let\PYG@it=\textit}
\def\PYG@tok@vc{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\def\PYG@tok@il{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\def\PYG@tok@go{\def\PYG@tc##1{\textcolor[rgb]{0.19,0.19,0.19}{##1}}}
\def\PYG@tok@cp{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\def\PYG@tok@gi{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\def\PYG@tok@gh{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\def\PYG@tok@ni{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.84,0.33,0.22}{##1}}}
\def\PYG@tok@nl{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.13,0.44}{##1}}}
\def\PYG@tok@nn{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\def\PYG@tok@no{\def\PYG@tc##1{\textcolor[rgb]{0.38,0.68,0.84}{##1}}}
\def\PYG@tok@na{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\def\PYG@tok@nb{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\def\PYG@tok@nc{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\def\PYG@tok@nd{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.33,0.33,0.33}{##1}}}
\def\PYG@tok@ne{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\def\PYG@tok@nf{\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.49}{##1}}}
\def\PYG@tok@si{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.44,0.63,0.82}{##1}}}
\def\PYG@tok@s2{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\def\PYG@tok@vi{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\def\PYG@tok@nt{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.45}{##1}}}
\def\PYG@tok@nv{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\def\PYG@tok@s1{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\def\PYG@tok@gp{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\def\PYG@tok@sh{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\def\PYG@tok@ow{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\def\PYG@tok@sx{\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\def\PYG@tok@bp{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\def\PYG@tok@c1{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\def\PYG@tok@kc{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\def\PYG@tok@c{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\def\PYG@tok@mf{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\def\PYG@tok@err{\def\PYG@bc##1{\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{##1}}}
\def\PYG@tok@kd{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\def\PYG@tok@ss{\def\PYG@tc##1{\textcolor[rgb]{0.32,0.47,0.09}{##1}}}
\def\PYG@tok@sr{\def\PYG@tc##1{\textcolor[rgb]{0.14,0.33,0.53}{##1}}}
\def\PYG@tok@mo{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\def\PYG@tok@mi{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\def\PYG@tok@kn{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\def\PYG@tok@o{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\def\PYG@tok@kr{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\def\PYG@tok@s{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\def\PYG@tok@kp{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\def\PYG@tok@w{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\def\PYG@tok@kt{\def\PYG@tc##1{\textcolor[rgb]{0.56,0.13,0.00}{##1}}}
\def\PYG@tok@sc{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\def\PYG@tok@sb{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\def\PYG@tok@k{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\def\PYG@tok@se{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\def\PYG@tok@sd{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}

\def\PYGZbs{\char`\\}
\def\PYGZus{\char`\_}
\def\PYGZob{\char`\{}
\def\PYGZcb{\char`\}}
\def\PYGZca{\char`\^}
\def\PYGZsh{\char`\#}
\def\PYGZpc{\char`\%}
\def\PYGZdl{\char`\$}
\def\PYGZti{\char`\~}
% for compatibility with earlier versions
\def\PYGZat{@}
\def\PYGZlb{[}
\def\PYGZrb{]}
\makeatother

\begin{document}

\maketitle
\tableofcontents
\phantomsection\label{index::doc}



\chapter{Contents:}
\label{index:welcome-to-pyfasst-s-documentation}\label{index:contents}

\section{pyFASST}
\label{description:pyfasst}\label{description::doc}\begin{quote}
\begin{quote}\begin{description}
\item[{contributors}] \leavevmode
Jean-Louis Durrieu

\item[{web}] \leavevmode
\href{https://git.epfl.ch/repo/pyfasst/}{https://git.epfl.ch/repo/pyfasst/} \href{https://github.com/wslihgt/pyfasst}{https://github.com/wslihgt/pyfasst}

\end{description}\end{quote}
\end{quote}

A Python implementation to the Flexible Audio Source Separation Toolbox


\subsection{Abstract}
\label{description:abstract}
This toolbox is meant to allow to use the framework FASST and extend it within a python program. It is primarily a re-write in Python of the original Matlab (C) version. The object programming framework allows to extend and create


\subsection{Using the Python package}
\label{description:using-the-python-package}

\subsubsection{Dependencies}
\label{description:dependencies}
Most of the code is written in \href{http://www.python.org}{Python}, but occasionally, there may be some C source code, requiring either Cython or SWIG for compiling. In general, to run this code, the required components are:
\begin{itemize}
\item {} 
Matplotlib \href{http://matplotlib.sourceforge.net}{http://matplotlib.sourceforge.net}

\item {} 
Numpy \href{http://numpy.scipy.org}{http://numpy.scipy.org}

\item {} 
Scipy \href{http://www.scipy.org}{http://www.scipy.org}

\item {} 
setuptool \href{https://pypi.python.org/pypi/setuptools}{https://pypi.python.org/pypi/setuptools}

\end{itemize}


\subsubsection{Install}
\label{description:install}
In addition to the aforementioned packages, installing this package requires to compile the tracking part, in \code{pyfasst.SeparateLeadStereo.tracking}.


\subsubsection{Examples}
\label{description:examples}\begin{itemize}
\item {} 
Using the provided audio model classes

\item {} 
Creating a new audio model class

\end{itemize}


\subsection{Algorithms}
\label{description:algorithms}
The FASST framework is described in {\hyperref[description:ozerov2012]{{[}Ozerov2012{]}}}. We have implemented this Python version mostly thanks to the provided Matlab (C) code available at \href{http://bass-db.gforge.inria.fr/fasst/}{http://bass-db.gforge.inria.fr/fasst/}.
\begin{description}
\item[{For initialization purposes, several side algorithms and systems have also been implemented:}] \leavevmode\begin{itemize}
\item {} 
SIMM model (Smooth Instantaneous Mixture Model) from {\hyperref[description:durrieu2010]{{[}Durrieu2010{]}}} and {\hyperref[description:durrieu2011]{{[}Durrieu2011{]}}}: allows to analyze, detect and separate the lead instrument from a polyphonic audio (musical) mixture. Note: the original purpose of this implementation was to provide a sensible way of using information from the SIMM model into the more general multi-channel audio source separation model provided, for instance, by FASST.

\item {} 
DEMIX algorithm (Direction Estimation of Mixing matrIX) {\hyperref[description:arberet2010]{{[}Arberet2010{]}}} for spatial mixing parameter initialization.

\end{itemize}

\end{description}


\subsection{References}
\label{description:references}

\section{Reference}
\label{reference::doc}\label{reference:reference}

\subsection{audioModel}
\label{reference/audiomodel:audiomodel}\label{reference/audiomodel::doc}\label{reference/audiomodel:module-pyfasst.audioModel}\index{pyfasst.audioModel (module)}
AudioModel:


\subsubsection{Description}
\label{reference/audiomodel:description}\begin{description}
\item[{FASST (Flexible Audio Source Separation Toolbox) class}] \leavevmode
subclass it to obtain your own flavoured source separation model!

\end{description}


\subsubsection{Usage}
\label{reference/audiomodel:usage}
TBD


\subsubsection{Reference}
\label{reference/audiomodel:reference}\begin{description}
\item[{..{[}Ozerov2012{]} A. Ozerov, E. Vincent and F. Bimbot}] \leavevmode
``A General Flexible Framework for the Handling of Prior Information
in Audio Source Separation,'' 
IEEE Transactions on Audio, Speech and Signal Processing 20(4),
pp. 1118-1133 (2012)                            
Available: \href{http://hal.inria.fr/hal-00626962/}{Archive on HAL}

\end{description}

Adapted from the Matlab toolbox available at
\href{http://bass-db.gforge.inria.fr/fasst/}{http://bass-db.gforge.inria.fr/fasst/}


\subsubsection{Copyright (TBD)}
\label{reference/audiomodel:copyright-tbd}
Jean-Louis Durrieu, EPFL-SSTI-IEL-LTS5

\begin{Verbatim}[commandchars=\\\{\}]
jean DASH louis AT durrieu DOT ch
\end{Verbatim}

2012-2013
\href{http://www.durrieu.ch}{http://www.durrieu.ch}


\subsubsection{Reference}
\label{reference/audiomodel:id1}\index{FASST (class in pyfasst.audioModel)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.FASST}\pysiglinewithargsret{\strong{class }\code{pyfasst.audioModel.}\bfcode{FASST}}{\emph{audio, transf='stft', wlen=2048, hopsize=512, iter\_num=50, sim\_ann\_opt='ann', ann\_PSD\_lim={[}None, None{]}, verbose=0, nmfUpdateCoeff=1.0, tffmin=25, tffmax=18000, tfWinFunc=None, tfbpo=48, lambdaCorr=0.0}}{}
\textbf{FASST audio model}, from {\hyperref[description:ozerov2012]{{[}Ozerov2012{]}}}
\index{GEM\_iteration() (pyfasst.audioModel.FASST method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.FASST.GEM_iteration}\pysiglinewithargsret{\bfcode{GEM\_iteration}}{}{}
GEM iteration

\end{fulllineitems}

\index{comp\_spat\_cmps\_powers() (pyfasst.audioModel.FASST method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.FASST.comp_spat_cmps_powers}\pysiglinewithargsret{\bfcode{comp\_spat\_cmps\_powers}}{\emph{spat\_comp\_ind}, \emph{spec\_comp\_ind=}\optional{}, \emph{factor\_ind=}\optional{}}{}
Compute the sum of the spectral powers corresponding to the
spatial components as provided in the list \emph{spat\_comp\_ind}

NB: because this does not take into account the mixing process,
the resulting power does not, in general, correspond to the
the observed signal's parameterized spectral power.

\end{fulllineitems}

\index{comp\_spat\_comp\_power() (pyfasst.audioModel.FASST method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.FASST.comp_spat_comp_power}\pysiglinewithargsret{\bfcode{comp\_spat\_comp\_power}}{\emph{spat\_comp\_ind}, \emph{spec\_comp\_ind=}\optional{}, \emph{factor\_ind=}\optional{}}{}
Matlab FASST Toolbox help:

\begin{Verbatim}[commandchars=\\\{\}]
\% V = comp\_spat\_comp\_power(mix\_str, spat\_comp\_ind,                  
\%                          spec\_comp\_ind, factor\_ind);            
\%
\% compute spatial component power
\%
\%
\% input
\% -----
\%
\% mix\_str           : mixture structure
\% spat\_comp\_ind     : spatial component index
\% spec\_comp\_ind     : (opt) factor index (def = [], use all components)
\% factor\_ind         : (opt) factor index (def = [], use all factors)
\% 
\%
\% output
\% ------
\%
\% V                 : (F x N) spatial component power
\end{Verbatim}

\end{fulllineitems}

\index{comp\_transf\_Cx() (pyfasst.audioModel.FASST method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.FASST.comp_transf_Cx}\pysiglinewithargsret{\bfcode{comp\_transf\_Cx}}{}{}
Computes the signal representation, according
to the provided signal\_representation flag

\end{fulllineitems}

\index{compute\_Wiener\_gain\_2d() (pyfasst.audioModel.FASST method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.FASST.compute_Wiener_gain_2d}\pysiglinewithargsret{\bfcode{compute\_Wiener\_gain\_2d}}{\emph{sigma\_comp\_diag}, \emph{sigma\_comp\_off}, \emph{inv\_sigma\_mix\_diag}, \emph{inv\_sigma\_mix\_off}, \emph{timeInvariant=False}}{}
Matlab FASST Toolbox help:

\begin{Verbatim}[commandchars=\\\{\}]
\% WG = comp\_WG\_spat\_comps(mix\_str);
\%
\% compute Wiener gains for spatial components
\%
\%
\% input
\% -----
\%
\% mix\_str           : input mix structure
\% 
\%
\% output
\% ------
\%
\% WG                : Wiener gains [M x M x F x N x K\_spat]
\%
\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%
\% Flexible Audio Source Separation Toolbox (FASST), Version 1.0
\%
\% Copyright 2011 Alexey Ozerov, Emmanuel Vincent and Frederic Bimbot
\% (alexey.ozerov -at- inria.fr, emmanuel.vincent -at- inria.fr,
\%  frederic.bimbot -at- irisa.fr)     
\%
\% This software is distributed under the terms of the GNU Public 
\% License version 3 (http://www.gnu.org/licenses/gpl.txt)
\%
\% If you use this code please cite this research report
\%
\% A. Ozerov, E. Vincent and F. Bimbot
\% "A General Flexible Framework for the Handling of Prior
\% Information in Audio Source Separation," 
\% IEEE Transactions on Audio, Speech and Signal Processing 20(4),
\% pp. 1118-1133 (2012).
\% Available: http://hal.inria.fr/hal-00626962/
\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%\%
\end{Verbatim}

\end{fulllineitems}

\index{compute\_inv\_sigma\_mix\_2d() (pyfasst.audioModel.FASST method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.FASST.compute_inv_sigma_mix_2d}\pysiglinewithargsret{\bfcode{compute\_inv\_sigma\_mix\_2d}}{\emph{sigma\_comps\_diag}, \emph{sigma\_comps\_off}}{}
only for nb channels = 2

sigma\_comps\_diag ncomp x nchan x nfreq x nframes

\end{fulllineitems}

\index{compute\_sigma\_comp\_2d() (pyfasst.audioModel.FASST method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.FASST.compute_sigma_comp_2d}\pysiglinewithargsret{\bfcode{compute\_sigma\_comp\_2d}}{\emph{spat\_ind}, \emph{spec\_comp\_ind}}{}
only for stereo case self.audioObject.channels==2

\end{fulllineitems}

\index{compute\_suff\_stat() (pyfasst.audioModel.FASST method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.FASST.compute_suff_stat}\pysiglinewithargsret{\bfcode{compute\_suff\_stat}}{\emph{spat\_comp\_powers}, \emph{mix\_matrix}}{}
Outputs:
\begin{quote}

hat\_Rxx
hat\_Rxs
hat\_Rss
hat\_Ws
loglik
\end{quote}

\end{fulllineitems}

\index{estim\_param\_a\_post\_model() (pyfasst.audioModel.FASST method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.FASST.estim_param_a_post_model}\pysiglinewithargsret{\bfcode{estim\_param\_a\_post\_model}}{}{}
Estimates the \emph{a posteriori} model for the provided
audio signal. In particular, this runs self.iter\_num times
the Generalized Expectation-Maximisation algorithm to
update the various parameters of the model, so as to
maximize the likelihood of the data given these parameters.

From these parameters, the posterior expectation of the
``hidden'' or latent variables (here the spatial and spectral
components) can be computed, leading to the estimation of the
separated underlying sources.

Consider using \code{self.separate\_spat\_comps} or
\code{self.separate\_spatial\_filter\_comp} to obtain the separated time
series, once the parameters have been estimated.

\end{fulllineitems}

\index{gcc\_phat\_tdoa\_2d() (pyfasst.audioModel.FASST method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.FASST.gcc_phat_tdoa_2d}\pysiglinewithargsret{\bfcode{gcc\_phat\_tdoa\_2d}}{}{}
Using the cross-spectrum in self.Cx{[}1{]} to estimate the time
difference of arrival detection function (the Generalized Cross-
Correllation GCC), with the phase transform (GCC-PHAT) weighing
function for the cross-spectrum.

\end{fulllineitems}

\index{initializeConvParams() (pyfasst.audioModel.FASST method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.FASST.initializeConvParams}\pysiglinewithargsret{\bfcode{initializeConvParams}}{\emph{initMethod='demix'}}{}
setting the spatial parameters

\end{fulllineitems}

\index{initialize\_all\_spec\_comps\_with\_NMF() (pyfasst.audioModel.FASST method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.FASST.initialize_all_spec_comps_with_NMF}\pysiglinewithargsret{\bfcode{initialize\_all\_spec\_comps\_with\_NMF}}{\emph{sameInitAll=False}, \emph{**kwargs}}{}
Computes an NMF on the one-channel mix (averaging diagonal
of self.Cx, which are the power spectra of the corresponding
channel)
\begin{gather}
\begin{split}C_x \approx W H\end{split}\notag
\end{gather}
then, for all spec\_comp in self.spec\_comps, we set:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{spec\PYGZus{}comp}\PYG{p}{[}\PYG{l+s}{'}\PYG{l+s}{FB}\PYG{l+s}{'}\PYG{p}{]} \PYG{o}{=} \PYG{n}{W}
\PYG{n}{spec\PYGZus{}comp}\PYG{p}{[}\PYG{l+s}{'}\PYG{l+s}{TW}\PYG{l+s}{'}\PYG{p}{]} \PYG{o}{=} \PYG{n}{H}
\end{Verbatim}

\end{fulllineitems}

\index{initialize\_all\_spec\_comps\_with\_NMF\_indiv() (pyfasst.audioModel.FASST method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.FASST.initialize_all_spec_comps_with_NMF_indiv}\pysiglinewithargsret{\bfcode{initialize\_all\_spec\_comps\_with\_NMF\_indiv}}{\emph{niter=10}, \emph{updateFreqBasis=True}, \emph{updateTimeWeight=True}, \emph{**kwargs}}{}
initialize the spectral components with an NMF decomposition,
with individual decomposition of the monophonic signal TF
representation.

TODO make keepFBind and keepTWind, in order to provide
finer control on which indices are updated. Also requires
a modified NMF decomposition function.

\end{fulllineitems}

\index{initialize\_all\_spec\_comps\_with\_NMF\_same() (pyfasst.audioModel.FASST method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.FASST.initialize_all_spec_comps_with_NMF_same}\pysiglinewithargsret{\bfcode{initialize\_all\_spec\_comps\_with\_NMF\_same}}{\emph{niter=10}, \emph{**kwargs}}{}
Initialize all the components with the same amplitude and spectral
matrices \emph{W} and \emph{H}.

\end{fulllineitems}

\index{mvdr\_2d() (pyfasst.audioModel.FASST method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.FASST.mvdr_2d}\pysiglinewithargsret{\bfcode{mvdr\_2d}}{\emph{theta}, \emph{distanceInterMic=0.3}}{}
mvdr\_2d(self,
theta, \# in radians
distanceInterMic=.3, \# in meters
)

MVDR minimum variance distortion-less response spatial
filter, for a given angle theta and given distance between the mics.

self.Cx is supposed to provide the necessary covariance matrix, for
the ``Capon'' filter.

\end{fulllineitems}

\index{renormalize\_parameters() (pyfasst.audioModel.FASST method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.FASST.renormalize_parameters}\pysiglinewithargsret{\bfcode{renormalize\_parameters}}{}{}
Re-normalize the components

\end{fulllineitems}

\index{retrieve\_subsrc\_params() (pyfasst.audioModel.FASST method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.FASST.retrieve_subsrc_params}\pysiglinewithargsret{\bfcode{retrieve\_subsrc\_params}}{}{}
Computes the various quantities necessary for the estimation of the
main parameters:
\begin{description}
\item[{\textbf{Outputs}}] \leavevmode\begin{description}
\item[{\code{spat\_comp\_powers}}] \leavevmode
(\code{total\_spat\_rank} x \code{nbFreqsSigRepr} x \code{nbFramesSigRepr}) ndarray
the spatial component power spectra. Note that total\_spat\_rank
is the sum of all the spatial ranks for all the sources.

\item[{mix\_matrix}] \leavevmode
(total\_spat\_rank x nchannels x nbFreqsSigRepr) ndarray
the mixing matrices for each source

\item[{rank\_part\_ind}] \leavevmode
dictionary: each key is one source, and the values are the indices
in \code{spat\_comp\_powers} and \code{mix\_matrix} that correspond to that source.
If the spatial rank of source \code{j} is 2, then its spectra will appear
twice in \code{spat\_comp\_powers}, with mixing parameters (potentially
different one from the other) appearing in two sub-matrices of
\code{mix\_matrix}.

\end{description}

\end{description}

\end{fulllineitems}

\index{separate\_comps() (pyfasst.audioModel.FASST method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.FASST.separate_comps}\pysiglinewithargsret{\bfcode{separate\_comps}}{\emph{dir\_results=None}, \emph{spec\_comp\_ind=None}, \emph{suffix=None}}{}
Separate the sources as defined by the spectral
components provided in spec\_comp\_ind.

This function differs from separate\_spat\_comps in the way
that it does not assume the sources are defined by their spatial
positions.

Note: Trying to bring into one method
ozerov's separate\_spec\_comps and separate\_spat\_comps

\end{fulllineitems}

\index{separate\_spat\_comps() (pyfasst.audioModel.FASST method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.FASST.separate_spat_comps}\pysiglinewithargsret{\bfcode{separate\_spat\_comps}}{\emph{dir\_results=None}, \emph{suffix=None}}{}
This separates the sources for each spatial component.

\end{fulllineitems}

\index{separate\_spatial\_filter\_comp() (pyfasst.audioModel.FASST method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.FASST.separate_spatial_filter_comp}\pysiglinewithargsret{\bfcode{separate\_spatial\_filter\_comp}}{\emph{dir\_results=None}, \emph{suffix=None}}{}
Separates the sources using only the estimated spatial
filter (i.e. the mixing parameters in self.spat\_comps{[}j{]}{[}'params'{]})

In particular, we consider here the corresponding MVDR filter,
as exposed in {\hyperref[reference/audiomodel:maazaoui2011]{{[}Maazaoui2011{]}}}.

per channel, the filter steering vector, source p:
\begin{gather}
\begin{split}b(f,p) = \frac{R_{aa,f}^{-1} a(f,p)}{a^{H}(f,p) R_{aa,f}^{-1} a(f,p)}\end{split}\notag
\end{gather}
with
\begin{gather}
\begin{split}R_{aa,f} = \sum_q a(f,q) a^{H}(f,q)\end{split}\notag
\end{gather}
It corresponds also to the given model in FASST, assuming that all the
spectral powers are equal across all sources. Here, by computing the Wiener
Gain WG to get the images, we actually have
\begin{gather}
\begin{split}b(f,p) a(f,p)^H\end{split}\notag
\end{gather}
and the denominator therefore is the trace of the ``numerator''.

\end{fulllineitems}

\index{setComponentParameter() (pyfasst.audioModel.FASST method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.FASST.setComponentParameter}\pysiglinewithargsret{\bfcode{setComponentParameter}}{\emph{newValue}, \emph{spec\_ind}, \emph{fact\_ind=0}, \emph{partLabel='FB'}, \emph{prior='free'}, \emph{keepDimensions=True}}{}
A helper function to set a
self.spec\_comp{[}spec\_ind{]}{[}'factor'{]}{[}fact\_ind{]}{[}partLabel{]} to
the given value.

TODO 20130522 finish this function to make it general purpose...

\end{fulllineitems}

\index{update\_mix\_matrix() (pyfasst.audioModel.FASST method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.FASST.update_mix_matrix}\pysiglinewithargsret{\bfcode{update\_mix\_matrix}}{\emph{hat\_Rxs}, \emph{hat\_Rss}, \emph{mix\_matrix}, \emph{rank\_part\_ind}}{}
\end{fulllineitems}

\index{update\_spectral\_components() (pyfasst.audioModel.FASST method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.FASST.update_spectral_components}\pysiglinewithargsret{\bfcode{update\_spectral\_components}}{\emph{hat\_W}}{}
Update the spectral components,
with hat\_W as the expected value of power

\end{fulllineitems}


\end{fulllineitems}

\index{MultiChanNMFConv (class in pyfasst.audioModel)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.MultiChanNMFConv}\pysiglinewithargsret{\strong{class }\code{pyfasst.audioModel.}\bfcode{MultiChanNMFConv}}{\emph{audio}, \emph{nbComps=3}, \emph{nbNMFComps=4}, \emph{spatial\_rank=2}, \emph{**kwargs}}{}
Takes the multichannel NMF instantaneous class, and makes it
convolutive!

\end{fulllineitems}

\index{MultiChanNMFInst\_FASST (class in pyfasst.audioModel)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.MultiChanNMFInst_FASST}\pysiglinewithargsret{\strong{class }\code{pyfasst.audioModel.}\bfcode{MultiChanNMFInst\_FASST}}{\emph{audio}, \emph{nbComps=3}, \emph{nbNMFComps=4}, \emph{spatial\_rank=2}, \emph{**kwargs}}{}
MultiChanNMFInst\_FASST

sub-classes FASST

This class implements the Multi-channel Non-Negative Matrix Factorisation
(NMF)
\index{setSpecCompFB() (pyfasst.audioModel.MultiChanNMFInst\_FASST method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.MultiChanNMFInst_FASST.setSpecCompFB}\pysiglinewithargsret{\bfcode{setSpecCompFB}}{\emph{compNb}, \emph{FB}, \emph{FB\_frdm\_prior='fixed'}}{}
SetSpecCompFB

sets the spectral component's frequency basis.

\end{fulllineitems}


\end{fulllineitems}

\index{multiChanSourceF0Filter (class in pyfasst.audioModel)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.multiChanSourceF0Filter}\pysiglinewithargsret{\strong{class }\code{pyfasst.audioModel.}\bfcode{multiChanSourceF0Filter}}{\emph{audio, nbComps=3, nbNMFResComps=1, nbFilterComps=20, nbFilterWeigs={[}4{]}, minF0=39, maxF0=2000, minF0search=80, maxF0search=800, stepnoteF0=16, chirpPerF0=1, spatial\_rank=1, sparsity=None, **kwargs}}{}
multi channel source/filter model
nbcomps components, nbcomps-1 SF models, 1 residual component
\index{estim\_param\_a\_post\_model() (pyfasst.audioModel.multiChanSourceF0Filter method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.multiChanSourceF0Filter.estim_param_a_post_model}\pysiglinewithargsret{\bfcode{estim\_param\_a\_post\_model}}{}{}
Estimation of model parameters, using the sparsity constraints.

\end{fulllineitems}

\index{initSpecCompsWithLabelAndFiles() (pyfasst.audioModel.multiChanSourceF0Filter method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.multiChanSourceF0Filter.initSpecCompsWithLabelAndFiles}\pysiglinewithargsret{\bfcode{initSpecCompsWithLabelAndFiles}}{\emph{instrus=}\optional{}, \emph{instru2modelfile=\{\}}, \emph{freqBasisAdaptive='fixed'}}{}
Initialize the spectral components with the instrument labels as
well as with the components stored in the provided dictionary in
\emph{instru2modelfile}
\begin{description}
\item[{\emph{instrus} is a list with labels:}] \leavevmode\begin{description}
\item[{\emph{`SourceFilter'}:}] \leavevmode
keep the intialized source filter model

\item[{\emph{`Free\_\textless{}nb\_comp\textgreater{}'}:}] \leavevmode
initialize the model with an adaptable
spectral component using \emph{nb\_comp} elements in the NMF
frequency basis

\item[{\emph{\textless{}key\_in\_instru2modelfile\textgreater{}}:}] \leavevmode
initialize with the :py:class:GSMM
available and stored in the archive npz with filename
\emph{instru2modelfile{[}key\_in\_instru2modelfile{]}}

\end{description}

\end{description}

NB: needs the gmm-gsmm module to be installed and in the pythonpath

\end{fulllineitems}

\index{initializeFreeMats() (pyfasst.audioModel.multiChanSourceF0Filter method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.multiChanSourceF0Filter.initializeFreeMats}\pysiglinewithargsret{\bfcode{initializeFreeMats}}{\emph{niter=10}}{}
initialize free matrices, with NMF decomposition

\end{fulllineitems}

\index{makeItConvolutive() (pyfasst.audioModel.multiChanSourceF0Filter method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.multiChanSourceF0Filter.makeItConvolutive}\pysiglinewithargsret{\bfcode{makeItConvolutive}}{}{}
Takes the spatial parameters and sets them to a convolutive
mixture, in case the parameter has not yet been changed to
`conv' mode.

\end{fulllineitems}

\index{reweigh\_sparsity\_constraint() (pyfasst.audioModel.multiChanSourceF0Filter method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.multiChanSourceF0Filter.reweigh_sparsity_constraint}\pysiglinewithargsret{\bfcode{reweigh\_sparsity\_constraint}}{\emph{sigma}}{}
\end{fulllineitems}

\index{setSpecCompFB() (pyfasst.audioModel.multiChanSourceF0Filter method)}

\begin{fulllineitems}
\phantomsection\label{reference/audiomodel:pyfasst.audioModel.multiChanSourceF0Filter.setSpecCompFB}\pysiglinewithargsret{\bfcode{setSpecCompFB}}{\emph{compNb}, \emph{FB}, \emph{FB\_frdm\_prior='fixed'}}{}
SetSpecCompFB

sets the spectral component's frequency basis.

\end{fulllineitems}


\end{fulllineitems}



\subsection{demix}
\label{reference/demix:module-pyfasst.demixTF}\label{reference/demix::doc}\label{reference/demix:demix}\index{pyfasst.demixTF (module)}
DEMIX Python/NumPy implementation


\subsubsection{Description}
\label{reference/demix:description}
DEMIX is an algorithm that counts the number of sources,
based on their spatial cues, and returns the estimated parameters,
which are related to the relative amplitudes between the channels,
as well as the relative time shifts. The full description is given
in:

\begin{Verbatim}[commandchars=\\\{\}]
Arberet, S.; Gribonval, R. \& Bimbot, F.
    A Robust Method to Count and Locate Audio Sources in
    a Multichannel Underdetermined Mixture
IEEE Transactions on Signal Processing, 2010, 58, 121 - 133
\end{Verbatim}

This implementation is based on the MATLAB Toolbox provided
by the authors of the above article.

Additionally, this implementation further allows time-frequency
representations other than the short-term Fourier transform (STFT).


\subsubsection{Copyright}
\label{reference/demix:copyright}
Jean-Louis Durrieu, EPFL-STI-IEL-LTS5

jean DASH louis AT durrieu DOT ch

2012-2013


\subsubsection{Reference}
\label{reference/demix:reference}\index{DEMIX (class in pyfasst.demixTF)}

\begin{fulllineitems}
\phantomsection\label{reference/demix:pyfasst.demixTF.DEMIX}\pysiglinewithargsret{\strong{class }\code{pyfasst.demixTF.}\bfcode{DEMIX}}{\emph{audio}, \emph{nsources=2}, \emph{wlen=2048}, \emph{hopsize=1024}, \emph{neighbors=20}, \emph{verbose=0}, \emph{maxclusters=100}, \emph{tfrepresentation='stft'}, \emph{tffmin=25}, \emph{tffmax=18000}, \emph{tfbpo=48}, \emph{winFunc=\textless{}function sqrt\_blackmanharris at 0x10262b488\textgreater{}}}{}
DEMIX algorithm, for 2 channels.
\index{adaptive\_thresholding\_clusters() (pyfasst.demixTF.DEMIX method)}

\begin{fulllineitems}
\phantomsection\label{reference/demix:pyfasst.demixTF.DEMIX.adaptive_thresholding_clusters}\pysiglinewithargsret{\bfcode{adaptive\_thresholding\_clusters}}{}{}
compute for each cluster in self.clusters a threshold depending
on the other clusters, in order to keep only those points in cluster
that are close to the actual centroid, but not close to centroids of
other clusters.

The returned clusters are the original clusters thresholded.

\end{fulllineitems}

\index{comp\_clusters() (pyfasst.demixTF.DEMIX method)}

\begin{fulllineitems}
\phantomsection\label{reference/demix:pyfasst.demixTF.DEMIX.comp_clusters}\pysiglinewithargsret{\bfcode{comp\_clusters}}{\emph{threshold=0.8}}{}
Computes the time-frequency clusters, along with their centroids,
which contain the parameters of the mixing process - namely \emph{theta},
which parameterizes the relative amplitude, and \emph{delta}, which is
homogeneous to a delay in samples between the two channels.

\end{fulllineitems}

\index{comp\_parameters() (pyfasst.demixTF.DEMIX method)}

\begin{fulllineitems}
\phantomsection\label{reference/demix:pyfasst.demixTF.DEMIX.comp_parameters}\pysiglinewithargsret{\bfcode{comp\_parameters}}{}{}
\end{fulllineitems}

\index{comp\_pcafeatures() (pyfasst.demixTF.DEMIX method)}

\begin{fulllineitems}
\phantomsection\label{reference/demix:pyfasst.demixTF.DEMIX.comp_pcafeatures}\pysiglinewithargsret{\bfcode{comp\_pcafeatures}}{}{}
Compute the PCA features

\end{fulllineitems}

\index{comp\_sig\_repr() (pyfasst.demixTF.DEMIX method)}

\begin{fulllineitems}
\phantomsection\label{reference/demix:pyfasst.demixTF.DEMIX.comp_sig_repr}\pysiglinewithargsret{\bfcode{comp\_sig\_repr}}{}{}
Computes the signal representation, stft

\end{fulllineitems}

\index{compute\_temporal() (pyfasst.demixTF.DEMIX method)}

\begin{fulllineitems}
\phantomsection\label{reference/demix:pyfasst.demixTF.DEMIX.compute_temporal}\pysiglinewithargsret{\bfcode{compute\_temporal}}{\emph{ind\_cluster\_pts}, \emph{zoom}}{}
This computes the inverse Fourier transform of the
estimated Steering Vectors, weighed by their inverse variance

The result is a detection function that provides peaks at the
most likely delta - the delay in samples.

\end{fulllineitems}

\index{create\_exclusive\_clusters() (pyfasst.demixTF.DEMIX method)}

\begin{fulllineitems}
\phantomsection\label{reference/demix:pyfasst.demixTF.DEMIX.create_exclusive_clusters}\pysiglinewithargsret{\bfcode{create\_exclusive\_clusters}}{}{}
reconfigures the cluster indices in self.clusters such
that all the Time-Freq points that appear in more than
one cluster are dismissed from all computations

\end{fulllineitems}

\index{estimDAOBound() (pyfasst.demixTF.DEMIX method)}

\begin{fulllineitems}
\phantomsection\label{reference/demix:pyfasst.demixTF.DEMIX.estimDAOBound}\pysiglinewithargsret{\bfcode{estimDAOBound}}{\emph{confidence}, \emph{confidenceVal=None}}{}
computes the max distance between centroid and points

\end{fulllineitems}

\index{getTFPointsNearDelta() (pyfasst.demixTF.DEMIX method)}

\begin{fulllineitems}
\phantomsection\label{reference/demix:pyfasst.demixTF.DEMIX.getTFPointsNearDelta}\pysiglinewithargsret{\bfcode{getTFPointsNearDelta}}{\emph{centroid}}{}
returns a TF mask which is True if their corresponding value of
\emph{delta} is close enough to the delta from the \emph{centroid}.

\end{fulllineitems}

\index{getTFpointsNearTheta\_OneScale() (pyfasst.demixTF.DEMIX method)}

\begin{fulllineitems}
\phantomsection\label{reference/demix:pyfasst.demixTF.DEMIX.getTFpointsNearTheta_OneScale}\pysiglinewithargsret{\bfcode{getTFpointsNearTheta\_OneScale}}{\emph{centroid\_tfpoint}}{}
returns the TF points whose theta is close to that of the centroid,
among the points considered in index\_pts\_to\_classify

TODO: make the function for different scales, as in matlab toolbox

\end{fulllineitems}

\index{get\_centroid\_distance() (pyfasst.demixTF.DEMIX method)}

\begin{fulllineitems}
\phantomsection\label{reference/demix:pyfasst.demixTF.DEMIX.get_centroid_distance}\pysiglinewithargsret{\bfcode{get\_centroid\_distance}}{}{}
distance between the centroids

\end{fulllineitems}

\index{identify\_deltaT() (pyfasst.demixTF.DEMIX method)}

\begin{fulllineitems}
\phantomsection\label{reference/demix:pyfasst.demixTF.DEMIX.identify_deltaT}\pysiglinewithargsret{\bfcode{identify\_deltaT}}{\emph{ind\_cluster\_pts}, \emph{centroid}, \emph{threshold=0.8}}{}
returns the delay maxDelta in samples that corresponds to the
largest peak of the cluster defined by the provided cluster index

\end{fulllineitems}

\index{reestimate\_clusterCentroids() (pyfasst.demixTF.DEMIX method)}

\begin{fulllineitems}
\phantomsection\label{reference/demix:pyfasst.demixTF.DEMIX.reestimate_clusterCentroids}\pysiglinewithargsret{\bfcode{reestimate\_clusterCentroids}}{}{}
reestimate cluster centroids

considering all the cluster masks, reestimate the centroids,
discarding the clusters for which there was no well-defined delta.

\end{fulllineitems}

\index{refine\_clusters() (pyfasst.demixTF.DEMIX method)}

\begin{fulllineitems}
\phantomsection\label{reference/demix:pyfasst.demixTF.DEMIX.refine_clusters}\pysiglinewithargsret{\bfcode{refine\_clusters}}{}{}
Refining the clusters in order to verify that they are possible.
Additionally, if self.nsources is defined, this method only keeps
the required number. Otherwise, it is decided by choosing the most
likely centroids.

\end{fulllineitems}

\index{remove\_empty\_clusters() (pyfasst.demixTF.DEMIX method)}

\begin{fulllineitems}
\phantomsection\label{reference/demix:pyfasst.demixTF.DEMIX.remove_empty_clusters}\pysiglinewithargsret{\bfcode{remove\_empty\_clusters}}{}{}
DJL: this did never happen in DEMIX Matlab version, have to contact
authors for explanations...

\end{fulllineitems}

\index{spatial\_filtering() (pyfasst.demixTF.DEMIX method)}

\begin{fulllineitems}
\phantomsection\label{reference/demix:pyfasst.demixTF.DEMIX.spatial_filtering}\pysiglinewithargsret{\bfcode{spatial\_filtering}}{}{}
using optimal spatial filters to obtain separated signals

this is a beamformer implementation.
MVDR or assuming the sources are normal, independent and
with same variance (not sure whether this does not mean that
we can't separate them...)

From:

\begin{Verbatim}[commandchars=\\\{\}]
Maazaoui, M.; Grenier, Y. \& Abed-Meraim, K.
{}`{}`Blind Source Separation for Robot Audition using
Fixed Beamforming with HRTFs'', 
in proc. of INTERSPEECH, 2011.
\end{Verbatim}

per channel, the filter steering vector, source p:
\begin{gather}
\begin{split}b(f,p) = \frac{R_{aa,f}^{-1} a(f,p)}{a^{H}(f,p) R_{aa,f}^{-1} a(f,p)}\end{split}\notag
\end{gather}
\end{fulllineitems}

\index{steeringVectorsFromCentroids() (pyfasst.demixTF.DEMIX method)}

\begin{fulllineitems}
\phantomsection\label{reference/demix:pyfasst.demixTF.DEMIX.steeringVectorsFromCentroids}\pysiglinewithargsret{\bfcode{steeringVectorsFromCentroids}}{}{}
Generates the steering vectors a(p,f,c) for source p,
(reduced) freq f and channel c.
\begin{gather}
\begin{split}a[p,f,0] = \cos(\theta_p)\end{split}\notag\\\begin{split}a[p,f,1] = \sin(\theta_p) \exp(- 2 j \pi f \delta_p)\end{split}\notag
\end{gather}
\end{fulllineitems}


\end{fulllineitems}

\index{confidenceFromVar() (in module pyfasst.demixTF)}

\begin{fulllineitems}
\phantomsection\label{reference/demix:pyfasst.demixTF.confidenceFromVar}\pysiglinewithargsret{\code{pyfasst.demixTF.}\bfcode{confidenceFromVar}}{\emph{variance}, \emph{neighbors}}{}
Computes the confidence, in dB, for a given number of
neighbours and a variance.

\end{fulllineitems}

\index{get\_indices\_peak() (in module pyfasst.demixTF)}

\begin{fulllineitems}
\phantomsection\label{reference/demix:pyfasst.demixTF.get_indices_peak}\pysiglinewithargsret{\code{pyfasst.demixTF.}\bfcode{get\_indices\_peak}}{\emph{sequence}, \emph{ind\_max}, \emph{threshold=0.8}}{}
returns the indices of the peak around ind\_max,
with values down to  \code{threshold * sequence{[}ind\_max{]}}

\end{fulllineitems}



\subsection{SeparateLeadStereo}
\label{reference/separateleadstereo:module-pyfasst.SeparateLeadStereo.SeparateLeadStereoTF}\label{reference/separateleadstereo:separateleadstereo}\label{reference/separateleadstereo::doc}\index{pyfasst.SeparateLeadStereo.SeparateLeadStereoTF (module)}
SeparateLeadStereo, with Time-Frequency choice

Provides a class (\code{SeparateLeadProcess}) within which several
processings can be run on an audio file, in order to extract the
lead instrument/main voice from a (stereophonic) audio mixture.

copyright (C) 2011 - 2013 Jean-Louis Durrieu
\index{SeparateLeadProcess (class in pyfasst.SeparateLeadStereo.SeparateLeadStereoTF)}

\begin{fulllineitems}
\phantomsection\label{reference/separateleadstereo:pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess}\pysiglinewithargsret{\strong{class }\code{pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.}\bfcode{SeparateLeadProcess}}{\emph{inputAudioFilename}, \emph{windowSize=0.0464}, \emph{hopsize=None}, \emph{NFT=None}, \emph{nbIter=10}, \emph{numCompAccomp=40}, \emph{minF0=39}, \emph{maxF0=2000}, \emph{stepNotes=16}, \emph{chirpPerF0=1}, \emph{K\_numFilters=4}, \emph{P\_numAtomFilters=30}, \emph{imageCanvas=None}, \emph{wavCanvas=None}, \emph{progressBar=None}, \emph{verbose=True}, \emph{outputDirSuffix='/'}, \emph{minF0search=None}, \emph{maxF0search=None}, \emph{tfrepresentation='stft'}, \emph{cqtfmax=4000}, \emph{cqtfmin=50}, \emph{cqtbins=48}, \emph{cqtWinFunc=\textless{}function sqrt\_blackmanharris at 0x10264d578\textgreater{}}, \emph{cqtAtomHopFactor=0.25}, \emph{initHF00='random'}, \emph{freeMemory=True}}{}
SeparateLeadProcess

class which implements the source separation algorithm, separating the
`lead' voice from the `accompaniment'. It can deal automatically with the
task (the `lead' voice becomes the most energetic one), or can be manually
told what the `lead' is (through the melody line).
\begin{description}
\item[{\textbf{Attributes}}] \leavevmode\begin{description}
\item[{dataType}] \leavevmode{[}dtype{]}
this is the input data type (usually the same as the audio encoding)

\item[{displayEvolution}] \leavevmode{[}boolean{]}
display the evolution of the arrays (notably HF0)

\item[{F, N}] \leavevmode{[}integer, integer{]}\begin{description}
\item[{F the number of frequency bins in the time-frequency representation}] \leavevmode
(this is half the Fourier bins, + 1)

\end{description}

N the number of analysis input frames

\item[{files :}] \leavevmode
dictionary containing the filenames of the output files for the
separated signals, with the following keys (after initialization)
\begin{quote}

`inputAudioFilename' : input filename

`mus\_output\_file' : output filename for the estimated
`accompaniment', appending `\_acc.wav' to the radical.

`outputDirSuffix' : the subfolder name to be appended to the path
of the directory of the input file, the output files will be
written in that subfolder

`outputDir' : the full path of the output files directory

`pathBaseName' : base name for the output files
(full path + radical for all output files)

`pitch\_output\_file' : output filename for the estimated melody line
appending `\_pitches.txt' to the radical.

`voc\_output\_file' : output filename for the estimated `lead
instrument', appending `\_voc.wav' to the radical.
\end{quote}

Additionally, the estimated `accompaniment' and `lead' with unvoiced
parts estimation are written to the corresponding filename without
these unvoiced parts, to which `\_VUIMM.wav' is appended.

\item[{imageCanvas}] \leavevmode{[}instance from MplCanvas or MplCanvas3Axes{]}
canvas used to draw the image of HF0

\item[{scaleData}] \leavevmode{[}double{]}
maximum value of the input data array.
With scipy.io.wavfile, the data array type is integer, and does not
fit well with the algorithm, so we need this scaleData parameter to
navigate back and forth between the double and integer representation.

\item[{scopeAllowedHF0}] \leavevmode{[}double{]}
scope of allowed F0s around the estimated/given melody line

\end{description}

stftParams : dictionary with the parameters for the time-frequency
representation (Short-Time Fourier Transform - STFT), with the keys:
\begin{quote}

`hopsize' : the step, in number of samples, between analysis
frames for the STFT

`NFT' : the number of Fourier bins on which the Fourier transforms
are computed.

`windowSizeInSamples' : analysis frame length, in samples
\end{quote}

SIMMParams : dictionary with the parameters of the SIMM model
(Smoothed Instantaneous Mixture Model {\hyperref[reference/separateleadstereo:drdf2010]{{[}DRDF2010{]}}}), with following keys:
\begin{quote}
\begin{description}
\item[{`alphaL', `alphaR'}] \leavevmode{[}double{]}
stereo model, panoramic parameters for the lead part

\item[{`betaL', `betaR'}] \leavevmode{[}(R,) ndarray{]}
stereo model, panoramic parameters for each of the component of
the accompaniment part.

\item[{`chirpPerF0'}] \leavevmode{[}integer{]}
number of F0s between two `stable' F0s, modelled
as chirps.

\item[{`F0Table'}] \leavevmode{[}(NF0,) ndarray{]}
frequency in Hz for each of the F0s appearing in WF0

\item[{`HF0'}] \leavevmode{[}(NF0*chirpPerF0, N) ndarray, \emph{estimated}{]}
amplitude array corresponding to the different F0s (this is
what you want if you want the visualisation representation of
the pitch saliances).

\item[{`HF00'}] \leavevmode{[}(NF0*chirpPerF0, N) ndarray, \emph{estimated}{]}
amplitude array HF0, after being zeroed everywhere outside
the given scope from the estimated melody

\item[{`HGAMMA'}] \leavevmode{[}(P, K) ndarray, \emph{estimated}{]}
amplitude array corresponding to the different smooth shapes,
decomposition of the filters on the smooth shapes in WGAMMA

\item[{`HM'}] \leavevmode{[}(R, N) ndarray, \emph{estimated}{]}
amplitude array corresponding to the decomposition of the
accompaniment on the spectral shapes in WM

\item[{`HPHI'}] \leavevmode{[}(K, N) ndarray, \emph{estimated}{]}
amplitude array corresponding to the decomposition of the
filter part on the filter spectral shapes in WPHI, defined
as np.dot(WGAMMA, HGAMMA)

\item[{`K'}] \leavevmode{[}integer{]}
number of filters for the filter part decomposition

\item[{`maxF0'}] \leavevmode{[}double{]}
the highest F0 candidate

\item[{`minF0'}] \leavevmode{[}double{]}
the lowest F0 candidate

\item[{`NF0'}] \leavevmode{[}integer{]}
number of F0s in total

\item[{`niter'}] \leavevmode{[}integer{]}
number of iterations for the estimation algorithm

\item[{`P'}] \leavevmode{[}integer{]}
number of smooth spectral shapes for the filter part (in WGAMMA)

\item[{`R'}] \leavevmode{[}integer{]}
number of spectral shapes for the accompaniment part (in WM)

\item[{`stepNotes'}] \leavevmode{[}integer{]}
number of F0s between two semitones

\item[{`WF0'}] \leavevmode{[}(F, NF0*chirpPerF0) ndarray, \emph{fixed}{]}
`dictionary' of harmonic spectral shapes for the F0 candidates
generated thanks to the KLGLOTT88 model {[}DRDF2010{]}

\item[{`WGAMMA'}] \leavevmode{[}(F, P) ndarray, \emph{fixed}{]}
`dictionary' of smooth spectral shapes for the filter part

\item[{`WM'}] \leavevmode{[}(F, R) ndarray, \emph{estimated}{]}
array of spectral shapes that are directly \emph{estimated} on the
signal

\end{description}
\end{quote}
\begin{description}
\item[{verbose}] \leavevmode{[}boolean{]}
if True, the program writes some information about what is happening

\item[{wavCanvas}] \leavevmode{[}instance from MplCanvas or MplCanvas3Axes{]}
the canvas that is going to be used to draw the input audio waveform

\item[{XL, XR}] \leavevmode{[}(F, N) ndarray{]}
resp. left and right channel STFT arrays

\end{description}

\end{description}

\textbf{Methods}
\begin{quote}
\begin{description}
\item[{Constructor}] \leavevmode{[}reads the input audio file, computes the STFT,{]}
generates the different dictionaries (for the source part,
harmonic patterns WF0, and for the filter part, smooth
patterns WGAMMA).

\item[{automaticMelodyAndSeparation :}] \leavevmode
launches sequence of methods to estimate the parameters, estimate the
melody, then re-estimate the parameters and at last separate the
lead from the rest, considering the lead is the most energetic source
of the mixture (with some continuity regularity)

\item[{estimSIMMParams :}] \leavevmode
estimates the parameters of the SIMM, i.e. HF0, HPHI, HGAMMA, HM and WM

\item[{estimStereoSIMMParams :}] \leavevmode
estimates the parameters of the stereo version of the SIMM,
i.e. same parameters as estimSIMMParams, with the alphas and betas

\item[{estimStereoSUIMMParams :}] \leavevmode
same as above, but first adds `noise' components to the source part

\item[{initiateHF0WithIndexBestPath :}] \leavevmode
computes the initial HF0, before the estimation, given the melody line
(estimated or not)

\item[{runViterbi :}] \leavevmode
estimates the melody line from HF0, the energies of each F0 candidates

\item[{setOutputFileNames :}] \leavevmode
triggered when the text fields are changed, changing the output
filenames

\item[{writeSeparatedSignals :}] \leavevmode
computing and writing the adaptive Wiener filtered separated files

\item[{{\hyperref[reference/separateleadstereo:pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess.writeSeparatedSignalsWithUnvoice]{\code{writeSeparatedSignalsWithUnvoice()}}} :}] \leavevmode
computing and writing the adaptive Wiener filtered separated files,
unvoiced parts.

\end{description}
\end{quote}

\textbf{References}

This is a class that encapsulates our work on source separation,
published as:

and

As of 3/1/2012, available at \href{http://www.durrieu.ch/research}{http://www.durrieu.ch/research}
\index{autoMelSepAndWrite() (pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess method)}

\begin{fulllineitems}
\phantomsection\label{reference/separateleadstereo:pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess.autoMelSepAndWrite}\pysiglinewithargsret{\bfcode{autoMelSepAndWrite}}{\emph{maxFrames=1000}}{}
Fully automated estimation of melody and separation of signals.

\end{fulllineitems}

\index{automaticMelodyAndSeparation() (pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess method)}

\begin{fulllineitems}
\phantomsection\label{reference/separateleadstereo:pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess.automaticMelodyAndSeparation}\pysiglinewithargsret{\bfcode{automaticMelodyAndSeparation}}{}{}
Fully automated estimation of melody and separation of signals.

\end{fulllineitems}

\index{checkChunkSize() (pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess method)}

\begin{fulllineitems}
\phantomsection\label{reference/separateleadstereo:pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess.checkChunkSize}\pysiglinewithargsret{\bfcode{checkChunkSize}}{\emph{maxFrames}}{}
Computes the number of chunks of size maxFrames, and
changes maxFrames in case it does not provide long enough
chunks (especially the last chunk).

\end{fulllineitems}

\index{computeChroma() (pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess method)}

\begin{fulllineitems}
\phantomsection\label{reference/separateleadstereo:pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess.computeChroma}\pysiglinewithargsret{\bfcode{computeChroma}}{\emph{maxFrames=3000}}{}
Compute the chroma matrix.

\end{fulllineitems}

\index{computeMonoX() (pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess method)}

\begin{fulllineitems}
\phantomsection\label{reference/separateleadstereo:pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess.computeMonoX}\pysiglinewithargsret{\bfcode{computeMonoX}}{\emph{start=0}, \emph{stop=None}}{}
Computes and return SX, the mono channel or mean over the
channels of the power spectrum of the signal

\end{fulllineitems}

\index{computeNFrames() (pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess method)}

\begin{fulllineitems}
\phantomsection\label{reference/separateleadstereo:pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess.computeNFrames}\pysiglinewithargsret{\bfcode{computeNFrames}}{}{}
compute Nb Frames:

\end{fulllineitems}

\index{computeWF0() (pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess method)}

\begin{fulllineitems}
\phantomsection\label{reference/separateleadstereo:pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess.computeWF0}\pysiglinewithargsret{\bfcode{computeWF0}}{}{}
Computes the frequency basis for the source part of SIMM,
if tfrepresentation is a CQT, it also computes the cqt/hybridcqt
transform object.

\end{fulllineitems}

\index{determineTuning() (pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess method)}

\begin{fulllineitems}
\phantomsection\label{reference/separateleadstereo:pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess.determineTuning}\pysiglinewithargsret{\bfcode{determineTuning}}{}{}
Determine Tuning by checking the peaks corresponding
to all possible patterns

\end{fulllineitems}

\index{estimHF0() (pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess method)}

\begin{fulllineitems}
\phantomsection\label{reference/separateleadstereo:pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess.estimHF0}\pysiglinewithargsret{\bfcode{estimHF0}}{\emph{R=1}, \emph{maxFrames=1000}}{}
estimating and storing only HF0 for the whole excerpt,
with only

\end{fulllineitems}

\index{estimStereoSIMMParamsWriteSeps() (pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess method)}

\begin{fulllineitems}
\phantomsection\label{reference/separateleadstereo:pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess.estimStereoSIMMParamsWriteSeps}\pysiglinewithargsret{\bfcode{estimStereoSIMMParamsWriteSeps}}{\emph{maxFrames=1000}}{}
Estimates the parameters little by little, by chunks,
and sequentially writes the signals. In the end, concatenates all these
separated signals into the desired output files

\end{fulllineitems}

\index{estimStereoSUIMMParamsWriteSeps() (pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess method)}

\begin{fulllineitems}
\phantomsection\label{reference/separateleadstereo:pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess.estimStereoSUIMMParamsWriteSeps}\pysiglinewithargsret{\bfcode{estimStereoSUIMMParamsWriteSeps}}{\emph{maxFrames=1000}}{}
same as estimStereoSIMMParamsWriteSeps, but adds the unvoiced
element in HF0

\end{fulllineitems}

\index{setOutputFileNames() (pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess method)}

\begin{fulllineitems}
\phantomsection\label{reference/separateleadstereo:pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess.setOutputFileNames}\pysiglinewithargsret{\bfcode{setOutputFileNames}}{\emph{outputDirSuffix}}{}
If already loaded a wav file, at this point, we can redefine
where we want the output files to be written.

Could be used, for instance, between the first estimation or the
Viterbi smooth estimation of the melody, and the re-estimation
of the parameters.

\end{fulllineitems}

\index{writeSeparatedSignals() (pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess method)}

\begin{fulllineitems}
\phantomsection\label{reference/separateleadstereo:pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess.writeSeparatedSignals}\pysiglinewithargsret{\bfcode{writeSeparatedSignals}}{\emph{suffix='.wav'}}{}
Writes the separated signals to the files in self.files.
If suffix contains `VUIMM', then this method will take
the WF0 and HF0 that contain the estimated unvoiced elements.

\end{fulllineitems}

\index{writeSeparatedSignalsWithUnvoice() (pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess method)}

\begin{fulllineitems}
\phantomsection\label{reference/separateleadstereo:pyfasst.SeparateLeadStereo.SeparateLeadStereoTF.SeparateLeadProcess.writeSeparatedSignalsWithUnvoice}\pysiglinewithargsret{\bfcode{writeSeparatedSignalsWithUnvoice}}{}{}
A wrapper to give a decent name to the function: simply
calling self.writeSeparatedSignals with the
`\_VUIMM.wav' suffix.

\end{fulllineitems}


\end{fulllineitems}



\subsection{separateLeadFunctions}
\label{reference/separateleadfunctions:separateleadfunctions}\label{reference/separateleadfunctions::doc}\label{reference/separateleadfunctions:module-pyfasst.SeparateLeadStereo.separateLeadFunctions}\index{pyfasst.SeparateLeadStereo.separateLeadFunctions (module)}
separateLeadFunctions.py


\subsubsection{Description}
\label{reference/separateleadfunctions:description}
This module provides functions that are useful for the SeparateLeadStereo
modules, essentially time-frequency transformations (and inverse), as well
as generation of dictionary matrices.


\subsubsection{Usage}
\label{reference/separateleadfunctions:usage}
See each function docstring for more information.

TODO: expend this?
TODO: move all these functions in different modules, in ..tools for instance


\subsubsection{License}
\label{reference/separateleadfunctions:license}
Copyright (C) 2011-2013 Jean-Louis Durrieu
\index{generateHannBasis() (in module pyfasst.SeparateLeadStereo.separateLeadFunctions)}

\begin{fulllineitems}
\phantomsection\label{reference/separateleadfunctions:pyfasst.SeparateLeadStereo.separateLeadFunctions.generateHannBasis}\pysiglinewithargsret{\code{pyfasst.SeparateLeadStereo.separateLeadFunctions.}\bfcode{generateHannBasis}}{\emph{numberFrequencyBins}, \emph{sizeOfFourier}, \emph{Fs}, \emph{frequencyScale='linear'}, \emph{numberOfBasis=20}, \emph{overlap=0.75}}{}
Generates a collection of Hann functions, spaced across the
frequency axis, as desired by the user (and if implemented),
targetting the given number of basis and adapting the extent (or bandwidth)
of each function (over the frequencies) to that number and according
to the desired overlap between these windows.

\end{fulllineitems}

\index{generate\_ODGD\_spec() (in module pyfasst.SeparateLeadStereo.separateLeadFunctions)}

\begin{fulllineitems}
\phantomsection\label{reference/separateleadfunctions:pyfasst.SeparateLeadStereo.separateLeadFunctions.generate_ODGD_spec}\pysiglinewithargsret{\code{pyfasst.SeparateLeadStereo.separateLeadFunctions.}\bfcode{generate\_ODGD\_spec}}{\emph{F0}, \emph{Fs}, \emph{lengthOdgd=2048}, \emph{Nfft=2048}, \emph{Ot=0.5}, \emph{t0=0.0}, \emph{analysisWindowType='sinebell'}}{}
generateODGDspec:

generates a waveform ODGD and the corresponding spectrum,
using as analysis window the -optional- window given as
argument.

\end{fulllineitems}

\index{generate\_ODGD\_spec\_chirped() (in module pyfasst.SeparateLeadStereo.separateLeadFunctions)}

\begin{fulllineitems}
\phantomsection\label{reference/separateleadfunctions:pyfasst.SeparateLeadStereo.separateLeadFunctions.generate_ODGD_spec_chirped}\pysiglinewithargsret{\code{pyfasst.SeparateLeadStereo.separateLeadFunctions.}\bfcode{generate\_ODGD\_spec\_chirped}}{\emph{F1}, \emph{F2}, \emph{Fs}, \emph{lengthOdgd=2048}, \emph{Nfft=2048}, \emph{Ot=0.5}, \emph{t0=0.0}, \emph{analysisWindowType='sinebell'}}{}
generateODGDspecChirped:

generates a waveform ODGD and the corresponding spectrum,
using as analysis window the -optional- window given as
argument.

\end{fulllineitems}

\index{generate\_ODGD\_spec\_inharmo() (in module pyfasst.SeparateLeadStereo.separateLeadFunctions)}

\begin{fulllineitems}
\phantomsection\label{reference/separateleadfunctions:pyfasst.SeparateLeadStereo.separateLeadFunctions.generate_ODGD_spec_inharmo}\pysiglinewithargsret{\code{pyfasst.SeparateLeadStereo.separateLeadFunctions.}\bfcode{generate\_ODGD\_spec\_inharmo}}{\emph{F0}, \emph{Fs}, \emph{lengthOdgd=2048}, \emph{Nfft=2048}, \emph{Ot=0.5}, \emph{t0=0.0}, \emph{analysisWindowType='sinebell'}, \emph{inharmonicity=0.5}}{}
generateODGDspec:

generates a waveform ODGD and the corresponding spectrum,
using as analysis window the -optional- window given as
argument.

\end{fulllineitems}

\index{generate\_WF0\_MinQT\_chirped() (in module pyfasst.SeparateLeadStereo.separateLeadFunctions)}

\begin{fulllineitems}
\phantomsection\label{reference/separateleadfunctions:pyfasst.SeparateLeadStereo.separateLeadFunctions.generate_WF0_MinQT_chirped}\pysiglinewithargsret{\code{pyfasst.SeparateLeadStereo.separateLeadFunctions.}\bfcode{generate\_WF0\_MinQT\_chirped}}{\emph{minF0}, \emph{maxF0}, \emph{cqtfmax}, \emph{cqtfmin}, \emph{cqtbins=48.0}, \emph{Fs=44100.0}, \emph{Nfft=2048}, \emph{stepNotes=4}, \emph{lengthWindow=2048}, \emph{Ot=0.5}, \emph{perF0=1}, \emph{depthChirpInSemiTone=0.5}, \emph{loadWF0=True}, \emph{analysisWindow='hanning'}, \emph{atomHopFactor=0.25}, \emph{cqtWinFunc=\textless{}function hanning at 0x1027e7c08\textgreater{}}, \emph{verbose=False}}{}~\begin{description}
\item[{F0Table, WF0 = generate\_WF0\_MinCQT\_chirped(minF0, maxF0, Fs, Nfft=2048,}] \leavevmode
stepNotes=4, lengthWindow=2048,
Ot=0.5, perF0=2,
depthChirpInSemiTone=0.5)

\end{description}

Generates a `basis' matrix for the source part WF0, using the
source model KLGLOTT88, with the following I/O arguments:
Inputs:
\begin{quote}
\begin{description}
\item[{minF0                the minimum value for the fundamental}] \leavevmode
frequency (F0)

\end{description}

maxF0                the maximum value for F0
cqtfmax...
Fs                   the desired sampling rate
Nfft                 the number of bins to compute the Fourier
\begin{quote}

transform
\end{quote}

stepNotes            the number of F0 per semitone
lengthWindow         the size of the window for the Fourier
\begin{quote}

transform
\end{quote}
\begin{description}
\item[{Ot                   the glottal opening coefficient for}] \leavevmode
KLGLOTT88

\item[{perF0                the number of chirps considered per F0}] \leavevmode
value

\item[{depthChirpInSemiTone the maximum value, in semitone, of the}] \leavevmode
allowed chirp per F0

\end{description}
\end{quote}
\begin{description}
\item[{Outputs:}] \leavevmode\begin{description}
\item[{F0Table the vector containing the values of the fundamental}] \leavevmode
frequencies in Hertz (Hz) corresponding to the
harmonic combs in WF0, i.e. the columns of WF0

\item[{WF0     the basis matrix, where each column is a harmonic comb}] \leavevmode
generated by KLGLOTT88 (with a sinusoidal model, then
transformed into the spectral domain)

\end{description}

\end{description}

20120828T2358 Horribly slow...

\end{fulllineitems}

\index{generate\_WF0\_NSGTMinQT\_chirped() (in module pyfasst.SeparateLeadStereo.separateLeadFunctions)}

\begin{fulllineitems}
\phantomsection\label{reference/separateleadfunctions:pyfasst.SeparateLeadStereo.separateLeadFunctions.generate_WF0_NSGTMinQT_chirped}\pysiglinewithargsret{\code{pyfasst.SeparateLeadStereo.separateLeadFunctions.}\bfcode{generate\_WF0\_NSGTMinQT\_chirped}}{\emph{minF0}, \emph{maxF0}, \emph{cqtfmax}, \emph{cqtfmin}, \emph{cqtbins=48.0}, \emph{Fs=44100.0}, \emph{Nfft=2048}, \emph{stepNotes=4}, \emph{lengthWindow=2048}, \emph{Ot=0.5}, \emph{perF0=1}, \emph{depthChirpInSemiTone=0.5}, \emph{loadWF0=True}, \emph{analysisWindow='hanning'}, \emph{atomHopFactor=0.25}, \emph{cqtWinFunc=\textless{}function hanning at 0x1027e7c08\textgreater{}}, \emph{verbose=False}}{}~\begin{description}
\item[{F0Table, WF0 = generate\_WF0\_MinCQT\_chirped(minF0, maxF0, Fs, Nfft=2048,}] \leavevmode
stepNotes=4, lengthWindow=2048,
Ot=0.5, perF0=2,
depthChirpInSemiTone=0.5)

\end{description}

Generates a `basis' matrix for the source part WF0, using the
source model KLGLOTT88, with the following I/O arguments:
Inputs:
\begin{quote}
\begin{description}
\item[{minF0                the minimum value for the fundamental}] \leavevmode
frequency (F0)

\end{description}

maxF0                the maximum value for F0
cqtfmax...
Fs                   the desired sampling rate
Nfft                 the number of bins to compute the Fourier
\begin{quote}

transform
\end{quote}

stepNotes            the number of F0 per semitone
lengthWindow         the size of the window for the Fourier
\begin{quote}

transform
\end{quote}
\begin{description}
\item[{Ot                   the glottal opening coefficient for}] \leavevmode
KLGLOTT88

\item[{perF0                the number of chirps considered per F0}] \leavevmode
value

\item[{depthChirpInSemiTone the maximum value, in semitone, of the}] \leavevmode
allowed chirp per F0

\end{description}
\end{quote}
\begin{description}
\item[{Outputs:}] \leavevmode\begin{description}
\item[{F0Table the vector containing the values of the fundamental}] \leavevmode
frequencies in Hertz (Hz) corresponding to the
harmonic combs in WF0, i.e. the columns of WF0

\item[{WF0     the basis matrix, where each column is a harmonic comb}] \leavevmode
generated by KLGLOTT88 (with a sinusoidal model, then
transformed into the spectral domain)

\end{description}

\end{description}

20120828T2358 Horribly slow...

\end{fulllineitems}

\index{generate\_WF0\_TR\_chirped() (in module pyfasst.SeparateLeadStereo.separateLeadFunctions)}

\begin{fulllineitems}
\phantomsection\label{reference/separateleadfunctions:pyfasst.SeparateLeadStereo.separateLeadFunctions.generate_WF0_TR_chirped}\pysiglinewithargsret{\code{pyfasst.SeparateLeadStereo.separateLeadFunctions.}\bfcode{generate\_WF0\_TR\_chirped}}{\emph{transform}, \emph{minF0}, \emph{maxF0}, \emph{stepNotes=4}, \emph{Ot=0.5}, \emph{perF0=1}, \emph{depthChirpInSemiTone=0.5}, \emph{loadWF0=True}, \emph{verbose=False}}{}
Generates a `basis' matrix for the source part WF0, using the
source model KLGLOTT88, with the following I/O arguments:
Inputs:
\begin{quote}
\begin{description}
\item[{minF0                the minimum value for the fundamental}] \leavevmode
frequency (F0)

\end{description}

maxF0                the maximum value for F0
cqtfmax...
Fs                   the desired sampling rate
Nfft                 the number of bins to compute the Fourier
\begin{quote}

transform
\end{quote}

stepNotes            the number of F0 per semitone
lengthWindow         the size of the window for the Fourier
\begin{quote}

transform
\end{quote}
\begin{description}
\item[{Ot                   the glottal opening coefficient for}] \leavevmode
KLGLOTT88

\item[{perF0                the number of chirps considered per F0}] \leavevmode
value

\item[{depthChirpInSemiTone the maximum value, in semitone, of the}] \leavevmode
allowed chirp per F0

\end{description}
\end{quote}
\begin{description}
\item[{Outputs:}] \leavevmode\begin{description}
\item[{F0Table the vector containing the values of the fundamental}] \leavevmode
frequencies in Hertz (Hz) corresponding to the
harmonic combs in WF0, i.e. the columns of WF0

\item[{WF0     the basis matrix, where each column is a harmonic comb}] \leavevmode
generated by KLGLOTT88 (with a sinusoidal model, then
transformed into the spectral domain)

\end{description}

\end{description}

20120828T2358 Horribly slow...

\end{fulllineitems}

\index{generate\_WF0\_chirped() (in module pyfasst.SeparateLeadStereo.separateLeadFunctions)}

\begin{fulllineitems}
\phantomsection\label{reference/separateleadfunctions:pyfasst.SeparateLeadStereo.separateLeadFunctions.generate_WF0_chirped}\pysiglinewithargsret{\code{pyfasst.SeparateLeadStereo.separateLeadFunctions.}\bfcode{generate\_WF0\_chirped}}{\emph{minF0}, \emph{maxF0}, \emph{Fs}, \emph{Nfft=2048}, \emph{stepNotes=4}, \emph{lengthWindow=2048}, \emph{Ot=0.5}, \emph{perF0=1}, \emph{depthChirpInSemiTone=0.5}, \emph{loadWF0=True}, \emph{analysisWindow='hanning'}}{}~\begin{description}
\item[{F0Table, WF0 = generate\_WF0\_chirped(minF0, maxF0, Fs, Nfft=2048,}] \leavevmode
stepNotes=4, lengthWindow=2048,
Ot=0.5, perF0=2,
depthChirpInSemiTone=0.5)

\end{description}

Generates a `basis' matrix for the source part WF0, using the
source model KLGLOTT88, with the following I/O arguments:
Inputs:
\begin{quote}
\begin{description}
\item[{minF0                the minimum value for the fundamental}] \leavevmode
frequency (F0)

\end{description}

maxF0                the maximum value for F0
Fs                   the desired sampling rate
Nfft                 the number of bins to compute the Fourier
\begin{quote}

transform
\end{quote}

stepNotes            the number of F0 per semitone
lengthWindow         the size of the window for the Fourier
\begin{quote}

transform
\end{quote}
\begin{description}
\item[{Ot                   the glottal opening coefficient for}] \leavevmode
KLGLOTT88

\item[{perF0                the number of chirps considered per F0}] \leavevmode
value

\item[{depthChirpInSemiTone the maximum value, in semitone, of the}] \leavevmode
allowed chirp per F0

\end{description}
\end{quote}
\begin{description}
\item[{Outputs:}] \leavevmode\begin{description}
\item[{F0Table the vector containing the values of the fundamental}] \leavevmode
frequencies in Hertz (Hz) corresponding to the
harmonic combs in WF0, i.e. the columns of WF0

\item[{WF0     the basis matrix, where each column is a harmonic comb}] \leavevmode
generated by KLGLOTT88 (with a sinusoidal model, then
transformed into the spectral domain)

\end{description}

\end{description}

\end{fulllineitems}



\begin{fulllineitems}
\pysigline{\bfcode{istft(X,~analysisWindow=None,~window=array({[}~0.~~~~~~~~,~~0.00153398,~~0.00306796,~...,~~0.00460193,}}\pysigline{\bfcode{0.00306796,~~0.00153398{]}),~hopsize=256.0,~nfft=2048.0,~originalDataLen=None,~start=-1,~stop=None)}}
data = istft(X, window=sinebell(2048), hopsize=256.0, nfft=2048.0)

Computes an inverse of the short time Fourier transform (STFT),
here, the overlap-add procedure is implemented.
\begin{description}
\item[{Inputs:}] \leavevmode
X                     : STFT of the signal, to be ``inverted''
window=sinebell(2048) : synthesis window
\begin{quote}

(should be the ``complementary'' window
for the analysis window)
\end{quote}

hopsize=1024.0        : hopsize for the analysis
nfft=2048.0           : number of points for the Fourier
\begin{quote}

computation
(the user has to provide an even number)
\end{quote}

\item[{Outputs:}] \leavevmode\begin{description}
\item[{data}] \leavevmode{[}time series corresponding to the given{]}
STFT the first half-window is removed,
complying with the STFT computation
given in the function `stft'

\end{description}

\end{description}

\end{fulllineitems}



\begin{fulllineitems}
\pysigline{\bfcode{stft(data,~window=array({[}~0.~~~~~~~~,~~0.00153398,~~0.00306796,~...,~~0.00460193,}}\pysigline{\bfcode{0.00306796,~~0.00153398{]}),~hopsize=256.0,~nfft=2048.0,~fs=44100.0,~start=0,~stop=None)}}~\begin{description}
\item[{X, F, N = stft(data, window=sinebell(2048), hopsize=1024.0,}] \leavevmode
nfft=2048.0, fs=44100)

\end{description}

Computes the short time Fourier transform (STFT) of data.
\begin{description}
\item[{Inputs:}] \leavevmode\begin{description}
\item[{data}] \leavevmode{[}one-dimensional time-series to be{]}
analyzed

\end{description}

window=sinebell(2048) : analysis window
hopsize=1024.0        : hopsize for the analysis
nfft=2048.0           : number of points for the Fourier
\begin{quote}

computation (the user has to provide an
even number)
\end{quote}

fs=44100.0            : sampling rate of the signal

\item[{Outputs:}] \leavevmode
X                     : STFT of data
F                     : values of frequencies at each Fourier
\begin{quote}

bins
\end{quote}
\begin{description}
\item[{N}] \leavevmode{[}central time at the middle of each{]}
analysis window

\end{description}

\end{description}

\end{fulllineitems}



\subsection{Spatial Signal Models}
\label{reference/spatial::doc}\label{reference/spatial:spatial-signal-models}
draws directivity diagrams for ULA assumption


\subsubsection{Contents}
\label{reference/spatial:module-pyfasst.spatial.dirdiag}\label{reference/spatial:contents}\index{pyfasst.spatial.dirdiag (module)}
dirdiag.py

Draw directivity diagrams

2013 Jean-Louis Durrieu
\href{http://www.durrieu.ch}{http://www.durrieu.ch}
\index{directivity\_filter\_diagram\_ULA() (in module pyfasst.spatial.dirdiag)}

\begin{fulllineitems}
\phantomsection\label{reference/spatial:pyfasst.spatial.dirdiag.directivity_filter_diagram_ULA}\pysiglinewithargsret{\code{pyfasst.spatial.dirdiag.}\bfcode{directivity\_filter\_diagram\_ULA}}{\emph{n\_sensors=2}, \emph{dist\_inter\_sensor=0.15}, \emph{w\_filter=None}, \emph{theta\_filter=0}, \emph{freqs=None}, \emph{thetas=None}, \emph{nfreqs=256}, \emph{nthetas=30}, \emph{samplerate=8000.0}, \emph{doplot=`2d'}, \emph{fig=None}, \emph{subplot\_number=(1}, \emph{1}, \emph{1)}, \emph{dyn\_func=\textless{}function db at 0x10262b230\textgreater{}}}{}
Computes and displays the directivity diagram associated to
the provided filter \code{w\_filter} (optionally parameterized by the
targetted direction \code{theta\_filter}).

the diagram can be interpreted as the amplitude of the filter for
a source at frequency \code{f}, located at an angle \code{theta} from
the the ULA array axis.

\end{fulllineitems}

\index{generate\_steer\_vec\_thetas() (in module pyfasst.spatial.dirdiag)}

\begin{fulllineitems}
\phantomsection\label{reference/spatial:pyfasst.spatial.dirdiag.generate_steer_vec_thetas}\pysiglinewithargsret{\code{pyfasst.spatial.dirdiag.}\bfcode{generate\_steer\_vec\_thetas}}{\emph{n\_sensors=2}, \emph{dist\_inter\_sensors=0.15}, \emph{freqs=None}, \emph{n\_freqs=256}, \emph{thetas=None}, \emph{n\_thetas=30}, \emph{samplerate=8000.0}, \emph{computeRaa=False}}{}
Generates a collection of steering vectors with the provided array and
signal parameters.

\end{fulllineitems}

\index{make\_MVDR\_filter\_target() (in module pyfasst.spatial.dirdiag)}

\begin{fulllineitems}
\phantomsection\label{reference/spatial:pyfasst.spatial.dirdiag.make_MVDR_filter_target}\pysiglinewithargsret{\code{pyfasst.spatial.dirdiag.}\bfcode{make\_MVDR\_filter\_target}}{\emph{steering\_vec\_target}, \emph{steering\_vec\_interf}}{}
make MVDR spatial filter from estimated steering vectors

\end{fulllineitems}

\index{produceMVDRplots() (in module pyfasst.spatial.dirdiag)}

\begin{fulllineitems}
\phantomsection\label{reference/spatial:pyfasst.spatial.dirdiag.produceMVDRplots}\pysiglinewithargsret{\code{pyfasst.spatial.dirdiag.}\bfcode{produceMVDRplots}}{\emph{theta\_filter=0.7853981633974483, freqs=None, n\_freqs=256, thetas=None, n\_thetas=30, samplerate=8000.0, n\_sensors=2, dist\_inter\_sensors=0.15, dists={[}0.15, 0.5, 1.0{]}, doplot=`2d', dyn\_func=\textless{}function db at 0x10262b230\textgreater{}, theta\_interf=None, n\_theta\_interf=4}}{}
MVDR gains for spatial filtering

\textbf{Description}:

Minimum Variance - Distortionless Response

\textbf{Examples}:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+go}{\textgreater{}\textgreater{}\textgreater{}\PYGZsh{} importing the module}
\PYG{g+go}{\textgreater{}\textgreater{}\textgreater{}import pyfasst.spatial.dirdiag as dd}
\PYG{g+go}{\textgreater{}\textgreater{}\textgreater{}\PYGZsh{} the MVDR plots, for 4 sensors and 4 interferers: visible rejection}
\PYG{g+go}{\textgreater{}\textgreater{}\textgreater{}Raa, w, th, fr, thetas, diag = dd.produceMVDRplots(n\PYGZus{}sensors=4, }
\PYG{g+go}{       n\PYGZus{}theta\PYGZus{}interf=2, samplerate=8000., dists=[0.15,])}
\PYG{g+go}{\textgreater{}\textgreater{}\textgreater{}\PYGZsh{} plotting also the filter responses against the angles}
\PYG{g+go}{\textgreater{}\textgreater{}\textgreater{}plt.figure();plt.plot(thetas,dd.db(diag))}
\PYG{g+go}{\textgreater{}\textgreater{}\textgreater{}plt.xlabel('\PYGZdl{}\PYGZbs{}theta\PYGZdl{} (rad)');plt.ylabel('Response (dB)')}
\PYG{g+go}{\textgreater{}\textgreater{}\textgreater{}\PYGZsh{} MVDR plots 2 sensors for 4 interferers: no rejection!}
\PYG{g+go}{\textgreater{}\textgreater{}\textgreater{}Raa, w, th, fr, thetas, diag = dd.produceMVDRplots(n\PYGZus{}sensors=2,}
\PYG{g+go}{       n\PYGZus{}theta\PYGZus{}interf=2, samplerate=8000., dists=[0.15,])}
\PYG{g+go}{\textgreater{}\textgreater{}\textgreater{}\PYGZsh{} plotting also the filter responses against the angles}
\PYG{g+go}{\textgreater{}\textgreater{}\textgreater{}plt.figure();plt.plot(thetas,dd.db(diag))}
\PYG{g+go}{\textgreater{}\textgreater{}\textgreater{}plt.xlabel('\PYGZdl{}\PYGZbs{}theta\PYGZdl{} (rad)');plt.ylabel('Response (dB)')}
\end{Verbatim}

\end{fulllineitems}

\index{producePicDiagramAgainstDistNSensors() (in module pyfasst.spatial.dirdiag)}

\begin{fulllineitems}
\phantomsection\label{reference/spatial:pyfasst.spatial.dirdiag.producePicDiagramAgainstDistNSensors}\pysiglinewithargsret{\code{pyfasst.spatial.dirdiag.}\bfcode{producePicDiagramAgainstDistNSensors}}{\emph{w\_filter=None}, \emph{theta\_filter=0.7853981633974483}, \emph{sensors=None}, \emph{dists=None}, \emph{samplerate=8000.0}, \emph{doplot=`2d'}, \emph{dyn\_func=\textless{}function db at 0x10262b230\textgreater{}}, \emph{thetas=None}, \emph{nthetas=30}}{}
generate a drawing that shows the directivity diagrams for
several values of distance between sensors and number of sensors.

\end{fulllineitems}

\phantomsection\label{reference/spatial:module-pyfasst.spatial.steering_vectors}\index{pyfasst.spatial.steering\_vectors (module)}

\paragraph{STEERING VECTORS}
\label{reference/spatial:steering-vectors}
generating steering vectors for arrays of sensors


\subparagraph{Content}
\label{reference/spatial:content}\index{dir\_diag\_stereo() (in module pyfasst.spatial.steering\_vectors)}

\begin{fulllineitems}
\phantomsection\label{reference/spatial:pyfasst.spatial.steering_vectors.dir_diag_stereo}\pysiglinewithargsret{\code{pyfasst.spatial.steering\_vectors.}\bfcode{dir\_diag\_stereo}}{\emph{Cx}, \emph{nft=2048}, \emph{ntheta=512}, \emph{samplerate=44100}, \emph{distanceInterMic=0.3}}{}
Compute the diagram of directivity for the input
short time Fourier transform second order statistics in Cx
(this Cx is compatible with the attribute from an instantiation
of {\hyperref[reference/audiomodel:pyfasst.audioModel.FASST]{\code{pyfasst.audioModel.FASST}}})
\begin{gather}
\begin{split}C_x[0] = E[|x_0|^2]\end{split}\notag\\\begin{split}C_x[2] = E[|x_1|^2]\end{split}\notag\\\begin{split}C_x[1] = E[x_0 x_1^H]\end{split}\notag
\end{gather}
\textbf{Method}:

We use the Capon method, on each of the Fourier channel $k$:
\begin{gather}
\begin{split}\phi_k(\theta) = a_k(\theta)^H R_{xx}^{-1} a_k(\theta)\end{split}\notag
\end{gather}
The algorithm therefore returns one directivity graph for each
frequency band.

\textbf{Remarks}:

One can compute a summary directivity by adding the directivity functions
across all the frequency channels. The invert of the resulting array may
also be of interest (looking at peaks and not valleys to find directions):

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{g+gp}{\textgreater{}\textgreater{}\textgreater{} }\PYG{n}{directivity\PYGZus{}diag} \PYG{o}{=} \PYG{n}{dir\PYGZus{}diag\PYGZus{}stereo}\PYG{p}{(}\PYG{n}{Cx}\PYG{p}{)}
\PYG{g+gp}{\textgreater{}\textgreater{}\textgreater{} }\PYG{n}{summary\PYGZus{}dir\PYGZus{}diag} \PYG{o}{=} \PYG{l+m+mf}{1.}\PYG{o}{/}\PYG{n}{directivity\PYGZus{}diag}\PYG{o}{.}\PYG{n}{sum}\PYG{p}{(}\PYG{n}{axis}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}
\end{Verbatim}

Some tests show that it is very important that the distance between the
microphone is known. Otherwise, little can be infered from the resulting
directivity measure...

\end{fulllineitems}

\index{gen\_steer\_vec\_acous() (in module pyfasst.spatial.steering\_vectors)}

\begin{fulllineitems}
\phantomsection\label{reference/spatial:pyfasst.spatial.steering_vectors.gen_steer_vec_acous}\pysiglinewithargsret{\code{pyfasst.spatial.steering\_vectors.}\bfcode{gen\_steer\_vec\_acous}}{\emph{freqs}, \emph{dist\_src\_mic}}{}
generates a steering vector for the given frequencies and given
distances between the microphones and the source.

To the difference with
{\hyperref[reference/spatial:pyfasst.spatial.steering_vectors.gen_steer_vec_far_src_uniform_linear_array]{\code{gen\_steer\_vec\_far\_src\_uniform\_linear\_array()}}}, this function
also includes gains depending on the distance between the source and
the mics.

\end{fulllineitems}

\index{gen\_steer\_vec\_far\_src\_uniform\_linear\_array() (in module pyfasst.spatial.steering\_vectors)}

\begin{fulllineitems}
\phantomsection\label{reference/spatial:pyfasst.spatial.steering_vectors.gen_steer_vec_far_src_uniform_linear_array}\pysiglinewithargsret{\code{pyfasst.spatial.steering\_vectors.}\bfcode{gen\_steer\_vec\_far\_src\_uniform\_linear\_array}}{\emph{freqs}, \emph{nchannels}, \emph{theta}, \emph{distanceInterMic}}{}
generate steering vector with relative far source,
uniformly spaced sensor array

\textbf{Description}:

assuming the source is far (compared to the dimensions of the array)
The sensor array is also assumed to be a linear array, the direction of
arrival (DOA) theta is defined as in the following incredible ASCII
art drawing:

\begin{Verbatim}[commandchars=\\\{\}]
  theta
-----\textgreater{}/              /
\textbar{}    /              /
y   /              /
   /              /
\textasciicircum{} /              /
\textbar{}/              /
+---\textgreater{} x
o    o    o    o    o    o
M1   M2   M3  ...
\textless{}---\textgreater{}
  d = distanceInterMic
\end{Verbatim}

That is more likely valid for electro-magnetic fields, for acoustic
wave fields, one should probably take into account the difference of
gain between the microphones (see {\hyperref[reference/spatial:pyfasst.spatial.steering_vectors.gen_steer_vec_acous]{\code{gen\_steer\_vec\_acous()}}} )

\textbf{Output}:
\begin{description}
\item[{a (nc, nfreqs) ndarray}] \leavevmode
contains the steering vectors, one for each channel, and

\end{description}

\end{fulllineitems}



\subsection{Time-Frequency Transforms}
\label{reference/tftransforms:time-frequency-transforms}\label{reference/tftransforms::doc}

\subsubsection{TFT module}
\label{reference/tftransforms:module-pyfasst.tftransforms.tft}\label{reference/tftransforms:tft-module}\index{pyfasst.tftransforms.tft (module)}
Time-Frequency Transforms

TODO: turn this into something more self-contained (like defining a super class
for all the possible time-freq transforms)


\subsubsection{STFT module}
\label{reference/tftransforms:module-pyfasst.tftransforms.stft}\label{reference/tftransforms:stft-module}\index{pyfasst.tftransforms.stft (module)}

\begin{fulllineitems}
\pysigline{\bfcode{filter\_conv\_stft(data,~W,~analysisWindow=None,~synthWindow=array({[}~0.~~~~~~~~,~~0.00153398,~~0.00306796,~...,~~0.00460193,}}\pysigline{\bfcode{0.00306796,~~0.00153398{]}),~hopsize=256.0,~nfft=2048.0,~fs=44100.0,~verbose=0)}}
Sequentially compute Fourier transfo, filter and overlap-add

INPUTS
\begin{quote}
\begin{description}
\item[{W}] \leavevmode
M x F x N (or M x F) filter for the data, which should be single channel

\item[{data}] \leavevmode
T (number of samples, number of channels)

\end{description}

...
\end{quote}

\end{fulllineitems}



\begin{fulllineitems}
\pysigline{\bfcode{filter\_stft(data,~W,~analysisWindow=None,~synthWindow=array({[}~0.~~~~~~~~,~~0.00153398,~~0.00306796,~...,~~0.00460193,}}\pysigline{\bfcode{0.00306796,~~0.00153398{]}),~hopsize=256.0,~nfft=2048.0,~fs=44100.0)}}
Sequentially compute Fourier transfo, filter and overlap-add

W is the M x M x F x N filter for the data, which should be T x M
data T x M (number of samples, number of channels)

\end{fulllineitems}



\begin{fulllineitems}
\pysigline{\bfcode{istft(X,~window=array({[}~0.~~~~~~~~,~~0.00153398,~~0.00306796,~...,~~0.00460193,}}\pysigline{\bfcode{0.00306796,~~0.00153398{]}),~analysisWindow=None,~hopsize=256.0,~nfft=2048.0)}}
data = istft(X,window=sinebell(2048),hopsize=1024.0,nfft=2048.0,fs=44100)

Computes an inverse of the short time Fourier transform (STFT),
here, the overlap-add procedure is implemented.
\begin{description}
\item[{Inputs:}] \leavevmode\begin{description}
\item[{X                     :}] \leavevmode
STFT of the signal, to be ``inverted''

\item[{window=sinebell(2048) :}] \leavevmode
synthesis window
(should be the ``complementary'' window
for the analysis window)

\item[{hopsize=1024.0        :}] \leavevmode
hopsize for the analysis

\item[{nfft=2048.0           :}] \leavevmode
number of points for the Fourier computation
(the user has to provide an even number)

\end{description}

\item[{Outputs:}] \leavevmode\begin{description}
\item[{data                  :}] \leavevmode
time series corresponding to the given STFT
the first half-window is removed, complying
with the STFT computation given in the
function stft

\end{description}

\end{description}

\end{fulllineitems}



\begin{fulllineitems}
\pysigline{\bfcode{stft(data,~window=array({[}~0.~~~~~~~~,~~0.00153398,~~0.00306796,~...,~~0.00460193,}}\pysigline{\bfcode{0.00306796,~~0.00153398{]}),~hopsize=256.0,~nfft=2048.0,~fs=44100.0)}}~\begin{description}
\item[{X, F, N = stft(data,window=sinebell(2048),hopsize=1024.0,}] \leavevmode
nfft=2048.0,fs=44100)

\end{description}

Computes the short time Fourier transform (STFT) of data.
\begin{description}
\item[{Inputs:}] \leavevmode\begin{description}
\item[{data                  :}] \leavevmode
one-dimensional time-series to be analyzed

\item[{window=sinebell(2048) :}] \leavevmode
analysis window

\item[{hopsize=1024.0        :}] \leavevmode
hopsize for the analysis

\item[{nfft=2048.0           :}] \leavevmode
number of points for the Fourier computation
(the user has to provide an even number)

\item[{fs=44100.0            :}] \leavevmode
sampling rate of the signal

\end{description}

\item[{Outputs:}] \leavevmode\begin{description}
\item[{X                     :}] \leavevmode
STFT of data

\item[{F                     :}] \leavevmode
values of frequencies at each Fourier bins

\item[{N                     :}] \leavevmode
central time at the middle of each analysis
window

\end{description}

\end{description}

\end{fulllineitems}



\subsubsection{MinQTmodule}
\label{reference/tftransforms:minqtmodule}\label{reference/tftransforms:module-pyfasst.tftransforms.minqt}\index{pyfasst.tftransforms.minqt (module)}
Constant-Q transform after the work by C. Scholkhuber and A. Klapuri
2010 {\hyperref[reference/tftransforms:sk2010]{{[}SK2010{]}}}

Adaptation of the Constant Q transform as presented in

Comments beginning with `\%' and `\%\%' are retained from the original Matlab
code.

Python/Numpy/Scipy by
Jean-Louis Durrieu, EPFL, 2012 - 2013
\index{CQTKernel (class in pyfasst.tftransforms.minqt)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.CQTKernel}\pysiglinewithargsret{\strong{class }\code{pyfasst.tftransforms.minqt.}\bfcode{CQTKernel}}{\emph{fmax}, \emph{bins}, \emph{fs}, \emph{q=1}, \emph{atomHopFactor=0.25}, \emph{thresh=0.0005}, \emph{winFunc=\textless{}function sqrt\_blackmanharris at 0x10267bc08\textgreater{}}, \emph{perfRast=0}}{}
The CQT Kernel contains everything that can be
precomputed for Constant-Q transforms. This
relies on {\hyperref[reference/tftransforms:sk2010]{{[}SK2010{]}}}, and therefore computes a Kernel
for a single octave. It is then efficiently used to
compute the decomposition on the different octaves by
downsampling the signal.

Parameters:
\begin{quote}
\begin{description}
\item[{fmax}] \leavevmode
The maximum desired central frequency

\item[{bins}] \leavevmode
The number of bins per octave

\item[{fs}] \leavevmode
Sampling rate of the audio files

\item[{q}] \leavevmode
parameter that controls the quality

\item[{atomHopFactor}] \leavevmode
hopsize rate (0.25 is a hopsize of 25\% the size of the windows)
between successive analysis windows

\item[{thresh}] \leavevmode
threshold value for sparsifying the kernel
(Note: in this implementation, we do not use the sparsity, more
efficiency could be achieved by considering it)

\item[{winFunc (python function that outputs an array)}] \leavevmode
the analysis window function

\item[{perfRast}] \leavevmode
whether computing rasterized version or not
(if so, the decompositions at all scales will have the same
number of frames, otherwise, each lower analysis octave will have
half as many frames as the direct upper analysis octave.)

\end{description}
\end{quote}

Attributes:
\begin{quote}

sparKernel
weight
atomHOP
FFTLen
fftOLP
fftHOP
bins
winNr
Nk\_max
Q 
fmin
fmax
frequencies
perfRast
first\_center
fs 
winFunc
thresh
q
\end{quote}

\end{fulllineitems}

\index{CQTransfo (class in pyfasst.tftransforms.minqt)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.CQTransfo}\pysiglinewithargsret{\strong{class }\code{pyfasst.tftransforms.minqt.}\bfcode{CQTransfo}}{\emph{fmin}, \emph{fmax}, \emph{bins}, \emph{fs}, \emph{q=1}, \emph{atomHopFactor=0.25}, \emph{thresh=0.0005}, \emph{winFunc=\textless{}function sqrt\_blackmanharris at 0x10267bc08\textgreater{}}, \emph{perfRast=0}, \emph{cqtkernel=None}, \emph{lowPassCoeffs=None}, \emph{data=None}, \emph{verbose=0}, \emph{**kwargs}}{}
Constant Q Transform
\index{cellCQT2spCQT() (pyfasst.tftransforms.minqt.CQTransfo method)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.CQTransfo.cellCQT2spCQT}\pysiglinewithargsret{\bfcode{cellCQT2spCQT}}{}{}
compute the full cqt from self.cellCQT

\end{fulllineitems}

\index{computeTransform() (pyfasst.tftransforms.minqt.CQTransfo method)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.CQTransfo.computeTransform}\pysiglinewithargsret{\bfcode{computeTransform}}{\emph{data}}{}
Computes the desired transform

\end{fulllineitems}

\index{freq\_stamps (pyfasst.tftransforms.minqt.CQTransfo attribute)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.CQTransfo.freq_stamps}\pysigline{\bfcode{freq\_stamps}}
frequency stamps for spCQT

\end{fulllineitems}

\index{invertFromCellCQT() (pyfasst.tftransforms.minqt.CQTransfo method)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.CQTransfo.invertFromCellCQT}\pysiglinewithargsret{\bfcode{invertFromCellCQT}}{}{}
inverting the Cell CQT

\end{fulllineitems}

\index{invertFromSpCQT() (pyfasst.tftransforms.minqt.CQTransfo method)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.CQTransfo.invertFromSpCQT}\pysiglinewithargsret{\bfcode{invertFromSpCQT}}{}{}
Assuming we have self.spCQT, and not self.cellCQT, we recompute
self.cellCQT from self.spCQT, and then invert as usual.

NB: here, self.cellCQT is written over, if it existed.

\end{fulllineitems}

\index{invertFromSpCQTRast() (pyfasst.tftransforms.minqt.CQTransfo method)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.CQTransfo.invertFromSpCQTRast}\pysiglinewithargsret{\bfcode{invertFromSpCQTRast}}{}{}
this inverts the transform, if perfRast, then this means
we can invert each hop of the different octaves.

\end{fulllineitems}

\index{invertTransform() (pyfasst.tftransforms.minqt.CQTransfo method)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.CQTransfo.invertTransform}\pysiglinewithargsret{\bfcode{invertTransform}}{}{}
Invert the desired transform, here invert CQT
from the cell CQT: like the original from {[}Schorkhuber2010{]}

\end{fulllineitems}

\index{qValues (pyfasst.tftransforms.minqt.CQTransfo attribute)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.CQTransfo.qValues}\pysigline{\bfcode{qValues}}
\$Q\$ values, approximated

\end{fulllineitems}

\index{spCQT (pyfasst.tftransforms.minqt.CQTransfo attribute)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.CQTransfo.spCQT}\pysigline{\bfcode{spCQT}}
spCQT: the constant Q transform, in a readable format.

\end{fulllineitems}

\index{spCQT2CellCQT() (pyfasst.tftransforms.minqt.CQTransfo method)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.CQTransfo.spCQT2CellCQT}\pysiglinewithargsret{\bfcode{spCQT2CellCQT}}{}{}
generates self.cellCQT from self.spCQT

NB: after transformation of spCQT (by filtering, for instance),
this method only keeps downsampled versions of each CQT representation
for each octave. More elaborated computations may be necessary to
take into account more precise time variations at low frequency
octaves.

\end{fulllineitems}

\index{time\_stamps (pyfasst.tftransforms.minqt.CQTransfo attribute)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.CQTransfo.time_stamps}\pysigline{\bfcode{time\_stamps}}
time stamps for spCQT

\end{fulllineitems}

\index{transfo (pyfasst.tftransforms.minqt.CQTransfo attribute)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.CQTransfo.transfo}\pysigline{\bfcode{transfo}}
returns the computed transform

\end{fulllineitems}


\end{fulllineitems}

\index{HybridCQTKernel (class in pyfasst.tftransforms.minqt)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.HybridCQTKernel}\pysiglinewithargsret{\strong{class }\code{pyfasst.tftransforms.minqt.}\bfcode{HybridCQTKernel}}{\emph{**kwargs}}{}
Hybrid CQT/Linear kernel
\index{computeMissingLinearFreqKernel() (pyfasst.tftransforms.minqt.HybridCQTKernel method)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.HybridCQTKernel.computeMissingLinearFreqKernel}\pysiglinewithargsret{\bfcode{computeMissingLinearFreqKernel}}{}{}
Compute the missing (high) frequency
components, and make a similar Kernel for them.

We can use this for the first octave (the highest frequency octave)
to extend the high frequencies. Actually, this can be used to compute
a hybrid CQT transform on the low frequencies, while keeping linear
freqs in the high spectrum, and still benefiting from the invertibility
of the CQT transform by Schoerkhuber and Klapuri

\end{fulllineitems}


\end{fulllineitems}

\index{HybridCQTransfo (class in pyfasst.tftransforms.minqt)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.HybridCQTransfo}\pysiglinewithargsret{\strong{class }\code{pyfasst.tftransforms.minqt.}\bfcode{HybridCQTransfo}}{\emph{**kwargs}}{}
Hybrid Constant Q Transform
\index{cellCQT2spCQT() (pyfasst.tftransforms.minqt.HybridCQTransfo method)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.HybridCQTransfo.cellCQT2spCQT}\pysiglinewithargsret{\bfcode{cellCQT2spCQT}}{}{}
the spCQT is computed from self.cellCQT

\end{fulllineitems}

\index{computeHybrid() (pyfasst.tftransforms.minqt.HybridCQTransfo method)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.HybridCQTransfo.computeHybrid}\pysiglinewithargsret{\bfcode{computeHybrid}}{\emph{data}}{}
calculates a hybrid CQT/FT representation of a sound stored in data

\end{fulllineitems}

\index{computeLinearPart() (pyfasst.tftransforms.minqt.HybridCQTransfo method)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.HybridCQTransfo.computeLinearPart}\pysiglinewithargsret{\bfcode{computeLinearPart}}{\emph{data}}{}
Same as computeCQT, except it uses the linear frequency components
in cqtkernel.linearSparKernel

NB: since this should be equivalent to computing an FFT after windowing
each frame, there may be a faster way of implementing this function.
For now, keeping the same rules as the original CQT implementation,
for consistency and also for avoiding problems with window synchrony

\end{fulllineitems}

\index{computeTransform() (pyfasst.tftransforms.minqt.HybridCQTransfo method)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.HybridCQTransfo.computeTransform}\pysiglinewithargsret{\bfcode{computeTransform}}{\emph{data}}{}
Computes the desired transform

\end{fulllineitems}

\index{invertHybridCQT() (pyfasst.tftransforms.minqt.HybridCQTransfo method)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.HybridCQTransfo.invertHybridCQT}\pysiglinewithargsret{\bfcode{invertHybridCQT}}{}{}
Invert the hybrid transform.

Linearity allows to perform the cqt inverse first, and add the inverse
of the linear freqs part thereafter (or the other way around).

\end{fulllineitems}

\index{invertLinearPart() (pyfasst.tftransforms.minqt.HybridCQTransfo method)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.HybridCQTransfo.invertLinearPart}\pysiglinewithargsret{\bfcode{invertLinearPart}}{}{}
This inverts the linear part of the hybrid transform

NB: as for the computation of this part in transform, a windowed
version
of a plain FFT should do the same job, and faster.

\end{fulllineitems}

\index{invertTransform() (pyfasst.tftransforms.minqt.HybridCQTransfo method)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.HybridCQTransfo.invertTransform}\pysiglinewithargsret{\bfcode{invertTransform}}{}{}
invert the desired transform

\end{fulllineitems}


\end{fulllineitems}

\index{MinQTKernel (class in pyfasst.tftransforms.minqt)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.MinQTKernel}\pysiglinewithargsret{\strong{class }\code{pyfasst.tftransforms.minqt.}\bfcode{MinQTKernel}}{\emph{bins}, \emph{fmax}, \emph{fs}, \emph{linFTLen=2048}, \emph{**kwargs}}{}
Min Q Transform Kernel
\index{computeMissingLinearFreqKernel() (pyfasst.tftransforms.minqt.MinQTKernel method)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.MinQTKernel.computeMissingLinearFreqKernel}\pysiglinewithargsret{\bfcode{computeMissingLinearFreqKernel}}{}{}
Compute the missing (high) frequency
components, and make a similar Kernel for them.

We can use this for the first octave (the highest frequency octave)
to extend the high frequencies. Actually, this can be used to compute
a hybrid CQT transform on the low frequencies, while keeping linear
freqs in the high spectrum, and still benefiting from the invertibility
of the CQT transform by Schoerkhuber and Klapuri

\end{fulllineitems}


\end{fulllineitems}

\index{MinQTransfo (class in pyfasst.tftransforms.minqt)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.MinQTransfo}\pysiglinewithargsret{\strong{class }\code{pyfasst.tftransforms.minqt.}\bfcode{MinQTransfo}}{\emph{fmax}, \emph{bins}, \emph{linFTLen}, \emph{fs}, \emph{fmin=70}, \emph{**kwargs}}{}
Minimum Q Transform
\index{cellCQT2spCQT() (pyfasst.tftransforms.minqt.MinQTransfo method)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.MinQTransfo.cellCQT2spCQT}\pysiglinewithargsret{\bfcode{cellCQT2spCQT}}{}{}
converts the cellCQT into a spCQT (matrix form)

\end{fulllineitems}

\index{computeLinearPart() (pyfasst.tftransforms.minqt.MinQTransfo method)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.MinQTransfo.computeLinearPart}\pysiglinewithargsret{\bfcode{computeLinearPart}}{\emph{data}}{}
Compute the linear frequency part with an STFT, and
taking only the desired frequencies.

\end{fulllineitems}

\index{computeTransform() (pyfasst.tftransforms.minqt.MinQTransfo method)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.MinQTransfo.computeTransform}\pysiglinewithargsret{\bfcode{computeTransform}}{\emph{data}}{}
Computes the desired transform

\end{fulllineitems}

\index{invertFromSpCQTRast() (pyfasst.tftransforms.minqt.MinQTransfo method)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.MinQTransfo.invertFromSpCQTRast}\pysiglinewithargsret{\bfcode{invertFromSpCQTRast}}{}{}
\end{fulllineitems}

\index{invertLinearPart() (pyfasst.tftransforms.minqt.MinQTransfo method)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.MinQTransfo.invertLinearPart}\pysiglinewithargsret{\bfcode{invertLinearPart}}{}{}
This inverts the linear part of the hybrid transform

NB: as for the computation of this part in transform, a windowed
version
of a plain FFT should do the same job, and faster.

\end{fulllineitems}

\index{invertTransform() (pyfasst.tftransforms.minqt.MinQTransfo method)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.MinQTransfo.invertTransform}\pysiglinewithargsret{\bfcode{invertTransform}}{}{}
invert the desired transform

\end{fulllineitems}

\index{linCellCQT2LinSpCQT() (pyfasst.tftransforms.minqt.MinQTransfo method)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.MinQTransfo.linCellCQT2LinSpCQT}\pysiglinewithargsret{\bfcode{linCellCQT2LinSpCQT}}{}{}
converts cellCQT{[}'linear'{]} into the corresponding bins in
self.\_spCQT

\end{fulllineitems}

\index{spCQT2CellCQT() (pyfasst.tftransforms.minqt.MinQTransfo method)}

\begin{fulllineitems}
\phantomsection\label{reference/tftransforms:pyfasst.tftransforms.minqt.MinQTransfo.spCQT2CellCQT}\pysiglinewithargsret{\bfcode{spCQT2CellCQT}}{}{}
Reverting spCQT (matrix form of the transform) back into
the (original?) cellCQT (one matrix per octave, one for the linear
part of the transform).

\end{fulllineitems}


\end{fulllineitems}



\subsection{TOOLS}
\label{reference/tools:tools}\label{reference/tools::doc}
The \code{tools} package contains various modules with different uses.


\subsubsection{DISTANCES}
\label{reference/tools:distances}\label{reference/tools:module-pyfasst.tools.distances}\index{pyfasst.tools.distances (module)}
distances.py

distance/divergence functions

2013 Jean-Louis Durrieu
\index{ISDistortion() (in module pyfasst.tools.distances)}

\begin{fulllineitems}
\phantomsection\label{reference/tools:pyfasst.tools.distances.ISDistortion}\pysiglinewithargsret{\code{pyfasst.tools.distances.}\bfcode{ISDistortion}}{\emph{X}, \emph{Y}}{}
value = ISDistortion(X, Y)

Returns the value of the Itakura-Saito (IS) divergence between
matrix X and matrix Y. X and Y should be two NumPy arrays with
same dimension.

\end{fulllineitems}



\subsubsection{NONNEGATIVE MATRIX FACTORIZATION}
\label{reference/tools:module-pyfasst.tools.nmf}\label{reference/tools:nonnegative-matrix-factorization}\index{pyfasst.tools.nmf (module)}
Simple Nonnegative Matrix Factorization (NMF) routines to be used
to estimate initial parameters in FASST.

Relevant references:
\index{NMF\_decomp\_init() (in module pyfasst.tools.nmf)}

\begin{fulllineitems}
\phantomsection\label{reference/tools:pyfasst.tools.nmf.NMF_decomp_init}\pysiglinewithargsret{\code{pyfasst.tools.nmf.}\bfcode{NMF\_decomp\_init}}{\emph{SX}, \emph{nbComps=10}, \emph{niter=10}, \emph{verbose=0}, \emph{Winit=None}, \emph{Hinit=None}, \emph{updateW=True}, \emph{updateH=True}}{}
NMF multiplicative gradient, for Itakura Saito
divergence measure between \code{SX} and \code{np.dot(W,H)}

See for instance {\hyperref[reference/tools:fevotte2009]{{[}Fevotte2009{]}}}.

Note: for (probably marginal) efficiency, the amplitude matrix \code{H}
is ``transposed'', such that its use in the \code{np.dot} operations uses
a C-ordered contiguous array. The output is however in the ``correct'' form.

\end{fulllineitems}

\index{NMF\_decomposition() (in module pyfasst.tools.nmf)}

\begin{fulllineitems}
\phantomsection\label{reference/tools:pyfasst.tools.nmf.NMF_decomposition}\pysiglinewithargsret{\code{pyfasst.tools.nmf.}\bfcode{NMF\_decomposition}}{\emph{SX}, \emph{nbComps=10}, \emph{niter=10}, \emph{verbose=0}}{}
NMF multiplicative gradient, for Itakura Saito
divergence measure between SX and \code{np.dot(W,H)}

See for instance {\hyperref[reference/tools:fevotte2009]{{[}Fevotte2009{]}}}.

\end{fulllineitems}

\index{SFNMF\_decomp\_init() (in module pyfasst.tools.nmf)}

\begin{fulllineitems}
\phantomsection\label{reference/tools:pyfasst.tools.nmf.SFNMF_decomp_init}\pysiglinewithargsret{\code{pyfasst.tools.nmf.}\bfcode{SFNMF\_decomp\_init}}{\emph{SX}, \emph{nbComps=10}, \emph{nbFiltComps=10}, \emph{niter=10}, \emph{verbose=0}, \emph{Winit=None}, \emph{Hinit=None}, \emph{WFiltInit=None}, \emph{HFiltInit=None}, \emph{updateW=True}, \emph{updateH=True}, \emph{updateWFilt=True}, \emph{updateHFilt=True}, \emph{nbResComps=2}}{}
Implements a simple source/filter NMF algorithm, similar to that introduced in
{\hyperref[description:durrieu2010]{{[}Durrieu2010{]}}}

\end{fulllineitems}



\subsubsection{UTILS}
\label{reference/tools:utils}\label{reference/tools:module-pyfasst.tools.utils}\index{pyfasst.tools.utils (module)}
\code{utils.py}

Useful functions for (audio) signal processing

2013 Jean-Louis Durrieu

\href{http://www.durrieu.ch}{http://www.durrieu.ch}


\paragraph{Content}
\label{reference/tools:content}\index{db() (in module pyfasst.tools.utils)}

\begin{fulllineitems}
\phantomsection\label{reference/tools:pyfasst.tools.utils.db}\pysiglinewithargsret{\code{pyfasst.tools.utils.}\bfcode{db}}{\emph{val}}{}
{\hyperref[reference/tools:pyfasst.tools.utils.db]{\code{db()}}} db(positiveValue)

Returns the decibel value of the input positiveValue

\end{fulllineitems}

\index{hann() (in module pyfasst.tools.utils)}

\begin{fulllineitems}
\phantomsection\label{reference/tools:pyfasst.tools.utils.hann}\pysiglinewithargsret{\code{pyfasst.tools.utils.}\bfcode{hann}}{\emph{args}}{}
window = hann(args)

Computes a Hann window, with NumPy's function hanning(args).

\end{fulllineitems}

\index{ident() (in module pyfasst.tools.utils)}

\begin{fulllineitems}
\phantomsection\label{reference/tools:pyfasst.tools.utils.ident}\pysiglinewithargsret{\code{pyfasst.tools.utils.}\bfcode{ident}}{\emph{energy}}{}
{\hyperref[reference/tools:pyfasst.tools.utils.ident]{\code{ident()}}} : identity function, return the inputs unchanged

\end{fulllineitems}

\index{nextpow2() (in module pyfasst.tools.utils)}

\begin{fulllineitems}
\phantomsection\label{reference/tools:pyfasst.tools.utils.nextpow2}\pysiglinewithargsret{\code{pyfasst.tools.utils.}\bfcode{nextpow2}}{\emph{i}}{}
Find $2^n$ that is equal to or greater than.

code taken from the website:
\begin{quote}

\href{http://www.phys.uu.nl/~haque/computing/WPark\_recipes\_in\_python.html}{http://www.phys.uu.nl/\textasciitilde{}haque/computing/WPark\_recipes\_in\_python.html}
\end{quote}

\end{fulllineitems}

\index{sinebell() (in module pyfasst.tools.utils)}

\begin{fulllineitems}
\phantomsection\label{reference/tools:pyfasst.tools.utils.sinebell}\pysiglinewithargsret{\code{pyfasst.tools.utils.}\bfcode{sinebell}}{\emph{lengthWindow}}{}
window = sinebell(lengthWindow)

Computes a ``sinebell'' window function of length L=lengthWindow

The formula is:
\begin{gather}
\begin{split}window(t) = sin(\pi \frac{t}{L}), t=0..L-1\end{split}\notag
\end{gather}
\end{fulllineitems}

\index{sqrt\_blackmanharris() (in module pyfasst.tools.utils)}

\begin{fulllineitems}
\phantomsection\label{reference/tools:pyfasst.tools.utils.sqrt_blackmanharris}\pysiglinewithargsret{\code{pyfasst.tools.utils.}\bfcode{sqrt\_blackmanharris}}{\emph{M}}{}
A root-squared Blackman-Harris window function.

For use in scholkhuber and klapuri's framework.

\end{fulllineitems}



\subsubsection{SIGNALTOOLS}
\label{reference/tools:signaltools}\label{reference/tools:module-pyfasst.tools.signalTools}\index{pyfasst.tools.signalTools (module)}
signalTools.py

gathers signal processing tools
\index{f0detectionFunction() (in module pyfasst.tools.signalTools)}

\begin{fulllineitems}
\phantomsection\label{reference/tools:pyfasst.tools.signalTools.f0detectionFunction}\pysiglinewithargsret{\code{pyfasst.tools.signalTools.}\bfcode{f0detectionFunction}}{\emph{TFmatrix}, \emph{freqs=None}, \emph{axis=None}, \emph{samplingrate=44100}, \emph{fouriersize=2048}, \emph{f0min=80}, \emph{f0max=3000}, \emph{stepnote=16}, \emph{numberHarmonics=20}, \emph{threshold=0.5}, \emph{detectFunc=\textless{}function sum at 0x10277a758\textgreater{}}, \emph{weightFreqs=None}, \emph{debug=False}}{}
Computes the Harmonic Sum

detectFunc should be a function taking an array as argument, and

\emph{threshold} is homogenous to a tone on the western musical scale

\end{fulllineitems}

\index{harmonicProd() (in module pyfasst.tools.signalTools)}

\begin{fulllineitems}
\phantomsection\label{reference/tools:pyfasst.tools.signalTools.harmonicProd}\pysiglinewithargsret{\code{pyfasst.tools.signalTools.}\bfcode{harmonicProd}}{\emph{TFmatrix}, \emph{**kwargs}}{}
Computes the harmonic sum

\end{fulllineitems}

\index{harmonicSum() (in module pyfasst.tools.signalTools)}

\begin{fulllineitems}
\phantomsection\label{reference/tools:pyfasst.tools.signalTools.harmonicSum}\pysiglinewithargsret{\code{pyfasst.tools.signalTools.}\bfcode{harmonicSum}}{\emph{TFmatrix}, \emph{**kwargs}}{}
Computes the harmonic sum

\end{fulllineitems}

\index{invHermMat2D() (in module pyfasst.tools.signalTools)}

\begin{fulllineitems}
\phantomsection\label{reference/tools:pyfasst.tools.signalTools.invHermMat2D}\pysiglinewithargsret{\code{pyfasst.tools.signalTools.}\bfcode{invHermMat2D}}{\emph{a\_00}, \emph{a\_01}, \emph{a\_11}}{}
This inverts a set of 2x2 Hermitian matrices

better check {\hyperref[reference/tools:pyfasst.tools.signalTools.inv_herm_mat_2d]{\code{inv\_herm\_mat\_2d()}}} instead, and replace all
reference to this by the former.

\end{fulllineitems}

\index{inv\_herm\_mat\_2d() (in module pyfasst.tools.signalTools)}

\begin{fulllineitems}
\phantomsection\label{reference/tools:pyfasst.tools.signalTools.inv_herm_mat_2d}\pysiglinewithargsret{\code{pyfasst.tools.signalTools.}\bfcode{inv\_herm\_mat\_2d}}{\emph{sigma\_x\_diag}, \emph{sigma\_x\_off}, \emph{verbose=False}}{}
Computes the inverse of 2D hermitian matrices.

\textbf{Inputs}
\begin{quote}
\begin{description}
\item[{sigma\_x\_diag}] \leavevmode
ndarray, with (dim of axis=0) = 2

The diagonal elements of the matrices to invert.
sigma\_x\_diag{[}0{]} are the (0,0) elements and
sigma\_x\_diag{[}1{]} are the (1,1) ones.

\item[{sigma\_x\_off}] \leavevmode
ndarray, with the same dimensions as sigma\_x\_diag{[}0{]}

The off-diagonal elements of the matrices, more precisely the
(0,1) element (since the matrices are assumed Hermitian,
the (1,0) element is the complex conjugate)

\end{description}
\end{quote}

\textbf{Outputs}
\begin{quote}
\begin{description}
\item[{inv\_sigma\_x\_diag}] \leavevmode
ndarray, 2 x shape(sigma\_x\_off)

Diagonal elements of the inverse matrices.
{[}0{]} \textless{}-\textgreater{} (0,0)
{[}1{]} \textless{}-\textgreater{} (1,1)

\item[{inv\_sigma\_x\_off}] \leavevmode
ndarray, shape(sigma\_x\_off)

Off-diagonal (0,1) elements of the inverse matrices

\item[{det\_sigma\_x}] \leavevmode
ndarray, shape(sigma\_x\_off)

For each inversion, the determinant of the matrix.

\end{description}
\end{quote}

\textbf{Remarks}
\begin{quote}

The inversion is done explicitly, by computing the determinant
(explicit formula for 2D matrices), then the elements of the
inverse with the corresponding formulas.

To deal with ill-conditioned matrices, a minimum (absolute) value of
the determinant is guaranteed.
\end{quote}

\end{fulllineitems}

\index{medianFilter() (in module pyfasst.tools.signalTools)}

\begin{fulllineitems}
\phantomsection\label{reference/tools:pyfasst.tools.signalTools.medianFilter}\pysiglinewithargsret{\code{pyfasst.tools.signalTools.}\bfcode{medianFilter}}{\emph{inputArray}, \emph{length=10}}{}
median filter

\end{fulllineitems}

\index{prinComp2D() (in module pyfasst.tools.signalTools)}

\begin{fulllineitems}
\phantomsection\label{reference/tools:pyfasst.tools.signalTools.prinComp2D}\pysiglinewithargsret{\code{pyfasst.tools.signalTools.}\bfcode{prinComp2D}}{\emph{X0}, \emph{X1}, \emph{neighborNb=10}, \emph{verbose=0}}{}
Computes the eigen values and eigen vectors for a
matrix X of shape 2 x F x N, computing the 2 x 2 covariance matrices
for the F x N over the temporal neighborhood of size neighborNb.

\end{fulllineitems}

\index{sortSpectrum() (in module pyfasst.tools.signalTools)}

\begin{fulllineitems}
\phantomsection\label{reference/tools:pyfasst.tools.signalTools.sortSpectrum}\pysiglinewithargsret{\code{pyfasst.tools.signalTools.}\bfcode{sortSpectrum}}{\emph{spectrum}, \emph{numberHarmonicsHS=50}, \emph{numberHarmonicsHP=1}, \emph{**kwargs}}{}
Sort the spectra in \code{spectrum} with respect to their F0
values, as estimated by HS * HP function.

20130521 DJL sort of works, but periodicity detection should be reworked
according to YIN and the like, in order to obtain better estimates.

\end{fulllineitems}



\section{Indices and tables}
\label{reference:indices-and-tables}\begin{itemize}
\item {} 
\emph{genindex}

\item {} 
\emph{modindex}

\item {} 
\emph{search}

\end{itemize}


\chapter{Indices and tables}
\label{index:indices-and-tables}\begin{itemize}
\item {} 
\emph{genindex}

\item {} 
\emph{modindex}

\item {} 
\emph{search}

\end{itemize}

\begin{thebibliography}{Maazaoui2011}
\bibitem[Arberet2010]{Arberet2010}{\phantomsection\label{description:arberet2010} 
Arberet, S.; Gribonval, R. and Bimbot, F.,
\emph{A Robust Method to Count and Locate Audio Sources in a Multichannel
Underdetermined Mixture}, IEEE Transactions on Signal Processing, 2010,
58, 121 - 133. {[}\href{http://infoscience.epfl.ch/record/150461/}{web}{]}
}
\bibitem[Durrieu2010]{Durrieu2010}{\phantomsection\label{description:durrieu2010} 
J.-L. Durrieu, G. Richard, B. David and C. F\textbackslash{}'\{e\}votte,
\emph{Source/Filter Model for Main Melody Extraction From Polyphonic Audio
Signals}, IEEE Transactions on Audio, Speech and Language Processing,
special issue on Signal Models and Representations of Musical and
Environmental Sounds, March 2010, Vol. 18 (3), pp. 564 -- 575.
}
\bibitem[Durrieu2011]{Durrieu2011}{\phantomsection\label{description:durrieu2011} 
J.-L. Durrieu, G. Richard and B. David,
\href{http://www.durrieu.ch/research/jstsp2010.html}{A Musically Motivated Representation For Pitch Estimation And Musical
Source Separation},
IEEE Journal of Selected Topics on Signal Processing, October 2011,
Vol. 5 (6), pp. 1180 - 1191.
}
\bibitem[Ozerov2012]{Ozerov2012}{\phantomsection\label{description:ozerov2012} 
A. Ozerov, E. Vincent, and F. Bimbot,
\href{http://hal.inria.fr/hal-00626962/}{A general flexible framework for the handling of prior information in audio
source separation},
IEEE Transactions on Audio, Speech and Signal Processing, Vol.  20 (4),
pp. 1118-1133 (2012).
}
\bibitem[Maazaoui2011]{Maazaoui2011}{\phantomsection\label{reference/audiomodel:maazaoui2011} 
Maazaoui, M.; Grenier, Y. and Abed-Meraim, K.
Blind Source Separation for Robot Audition using
Fixed Beamforming with HRTFs, 
in proc. of INTERSPEECH, 2011.
}
\bibitem[DDR2011]{DDR2011}{\phantomsection\label{reference/separateleadstereo:ddr2011} 
J.-L. Durrieu, B. David and G. Richard,
A Musically Motivated Mid-Level Representation
For Pitch Estimation And Musical Audio Source Separation,
IEEE Journal of Selected Topics on Signal Processing,
October 2011, Vol. 5 (6), pp. 1180 - 1191.
}
\bibitem[DRDF2010]{DRDF2010}{\phantomsection\label{reference/separateleadstereo:drdf2010} 
J.-L. Durrieu, G. Richard, B. David and C. F'evotte,
Source/Filter Model for Main Melody Extraction
From Polyphonic Audio Signals,
IEEE Transactions on Audio, Speech and Language Processing,
special issue on Signal Models and Representations of Musical
and Environmental Sounds, March 2010, vol. 18 (3), pp. 564 -- 575.
}
\bibitem[SK2010]{SK2010}{\phantomsection\label{reference/tftransforms:sk2010} 
Schoerkhuber, C. and Klapuri, A.,
``Constant-Q transform toolbox for music processing,''
submitted to the 7th Sound and Music Computing Conference, Barcelona, Spain.
}
\bibitem[Durrieu2010]{Durrieu2010}{\phantomsection\label{reference/tools:durrieu2010} 
J.-L. Durrieu, G. Richard, B. David and C. Fevotte,
Source/Filter Model for Main Melody Extraction From Polyphonic Audio 
Signals, IEEE Transactions on Audio, Speech and Language Processing, 
special issue on Signal Models and Representations of Musical and 
Environmental Sounds, March 2010, Vol. 18 (3), pp. 564 -- 575.
}
\bibitem[Fevotte2009]{Fevotte2009}{\phantomsection\label{reference/tools:fevotte2009} 
C. Fevotte and N. Bertin and J.-L. Durrieu,
Nonnegative matrix factorization with the Itakura-Saito divergence.
With application to music analysis,
Neural Computation, vol. 21 (3), pp. 793-830, March 2009.
{[}\href{http://www.unice.fr/cfevotte/publications/journals/neco09\_is-nmf.pdf}{pdf}{]}
}
\end{thebibliography}


\renewcommand{\indexname}{Python Module Index}
\begin{theindex}
\def\bigletter#1{{\Large\sffamily#1}\nopagebreak\vspace{1mm}}
\bigletter{p}
\item {\texttt{pyfasst.audioModel}}, \pageref{reference/audiomodel:module-pyfasst.audioModel}
\item {\texttt{pyfasst.demixTF}}, \pageref{reference/demix:module-pyfasst.demixTF}
\item {\texttt{pyfasst.SeparateLeadStereo.separateLeadFunctions}}, \pageref{reference/separateleadfunctions:module-pyfasst.SeparateLeadStereo.separateLeadFunctions}
\item {\texttt{pyfasst.SeparateLeadStereo.SeparateLeadStereoTF}}, \pageref{reference/separateleadstereo:module-pyfasst.SeparateLeadStereo.SeparateLeadStereoTF}
\item {\texttt{pyfasst.spatial.dirdiag}}, \pageref{reference/spatial:module-pyfasst.spatial.dirdiag}
\item {\texttt{pyfasst.spatial.steering\_vectors}}, \pageref{reference/spatial:module-pyfasst.spatial.steering_vectors}
\item {\texttt{pyfasst.tftransforms.minqt}}, \pageref{reference/tftransforms:module-pyfasst.tftransforms.minqt}
\item {\texttt{pyfasst.tftransforms.stft}}, \pageref{reference/tftransforms:module-pyfasst.tftransforms.stft}
\item {\texttt{pyfasst.tftransforms.tft}}, \pageref{reference/tftransforms:module-pyfasst.tftransforms.tft}
\item {\texttt{pyfasst.tools.distances}}, \pageref{reference/tools:module-pyfasst.tools.distances}
\item {\texttt{pyfasst.tools.nmf}}, \pageref{reference/tools:module-pyfasst.tools.nmf}
\item {\texttt{pyfasst.tools.signalTools}}, \pageref{reference/tools:module-pyfasst.tools.signalTools}
\item {\texttt{pyfasst.tools.utils}}, \pageref{reference/tools:module-pyfasst.tools.utils}
\end{theindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}
